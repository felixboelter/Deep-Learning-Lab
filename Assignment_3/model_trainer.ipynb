{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torchtext==0.10.0"
      ],
      "metadata": {
        "id": "2r8xNK8JGGps",
        "outputId": "18601d0a-2930-4a48-c9ba-126b2d5342f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchtext==0.10.0\n",
            "  Downloading torchtext-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 36.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (2.23.0)\n",
            "Collecting torch==1.9.0\n",
            "  Downloading torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 831.4 MB 2.6 kB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchtext==0.10.0) (4.1.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2.10)\n",
            "Installing collected packages: torch, torchtext\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.1+cu113\n",
            "    Uninstalling torch-1.12.1+cu113:\n",
            "      Successfully uninstalled torch-1.12.1+cu113\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.13.1\n",
            "    Uninstalling torchtext-0.13.1:\n",
            "      Successfully uninstalled torchtext-0.13.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.13.1+cu113 requires torch==1.12.1, but you have torch 1.9.0 which is incompatible.\n",
            "torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.9.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.9.0 torchtext-0.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/felixboelter/Deep-Learning-Lab\n",
        "%cd Deep-Learning-Lab/Assignment_3"
      ],
      "metadata": {
        "id": "zRPvqLjWGGa3",
        "outputId": "ac85f462-91c0-4841-e3da-023bab072f31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Deep-Learning-Lab'...\n",
            "remote: Enumerating objects: 97, done.\u001b[K\n",
            "remote: Counting objects: 100% (97/97), done.\u001b[K\n",
            "remote: Compressing objects: 100% (78/78), done.\u001b[K\n",
            "remote: Total 97 (delta 27), reused 84 (delta 16), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (97/97), done.\n",
            "/content/Deep-Learning-Lab/Assignment_3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVXdUxCGGFUo"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "3YzLHKS8GFUs"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import os\n",
        "import numpy as np\n",
        "from torchtext.legacy.data import Field\n",
        "from torchtext.legacy.datasets import LanguageModelingDataset\n",
        "from torchtext.legacy.data import BPTTIterator\n",
        "from src.model import LSTMModel\n",
        "from src.helper import counter, get_fables\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameters"
      ],
      "metadata": {
        "id": "GKjbsi9UaNCa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "EMBEDDING_DIM = 1024\n",
        "HIDDEN_SIZE = 1024\n",
        "LAYERS = 2\n",
        "BPTT_LEN = 256\n",
        "model_parameters = {\n",
        "    'batch_size' : BATCH_SIZE,\n",
        "    'embedding_dim': EMBEDDING_DIM,\n",
        "    'hidden_size': HIDDEN_SIZE,\n",
        "    'num_layers': LAYERS\n",
        "}\n",
        "bonus_path = os.path.join('data', \"donaldtrump.txt\")\n",
        "book_path = os.path.join(os.path.join(\"data\",\"books\"), \"AesopsFables.txt\")"
      ],
      "metadata": {
        "id": "vvY6O70aaMV0"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmiBZ3zuGFUu"
      },
      "source": [
        "# Training Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ywD9xE1BGFUu"
      },
      "outputs": [],
      "source": [
        "class Trainer():\n",
        "    def __init__(self, model_parameters : dict, path : str, bptt_len : int, samples : list):\n",
        "        self.samples = samples\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        _split_chars = lambda x: list(x) \n",
        "        self.train_field = Field(tokenize=_split_chars ,init_token ='<sos>',eos_token ='<eos>')\n",
        "        train_dataset = LanguageModelingDataset(\n",
        "            path = path,\n",
        "            text_field=self.train_field\n",
        "        )\n",
        "        self.train_field.build_vocab(train_dataset)\n",
        "        self.bptt_iterator = BPTTIterator(\n",
        "            dataset= train_dataset,\n",
        "            batch_size = model_parameters['batch_size'],\n",
        "            bptt_len = bptt_len,\n",
        "            shuffle = False\n",
        "        )\n",
        "        self.model = LSTMModel(**model_parameters, vocab_size = len(self.train_field.vocab)).to(self.device)\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=0.001)\n",
        "\n",
        "        \n",
        "    def predict(self, model : LSTMModel, prompt : str,sequence_length : int, method : str = 'greedy') -> str:\n",
        "        \"\"\"\n",
        "        The function takes in a model, a prompt, a sequence length, and a method. It then generates a\n",
        "        sentence of the specified length using the specified method\n",
        "        \n",
        "        :param model: the model to use for prediction\n",
        "        :type model: LSTMModel\n",
        "        :param prompt: The prompt to start the sentence with\n",
        "        :type prompt: str\n",
        "        :param sequence_length: The length of the generated sequence\n",
        "        :type sequence_length: int\n",
        "        :param method: 'greedy' or 'random', defaults to greedy\n",
        "        :type method: str (optional)\n",
        "        :return: A string of the generated sentence\n",
        "        \"\"\"\n",
        "        model.eval()\n",
        "        generated_sentence=[]\n",
        "        prompt = torch.tensor([self.train_field.vocab.stoi[t] for t in self.train_field.tokenize(prompt)]).long().to(self.device)\n",
        "        hidden = None\n",
        "        Softmax1D = nn.Softmax(dim=1)\n",
        "        if method == 'greedy':\n",
        "            out,hidden=model(prompt.view(-1,1),hidden)\n",
        "            ix = torch.argmax(Softmax1D(out), dim=1)[len(prompt)-1]\n",
        "            for i in range(sequence_length):\n",
        "                out,hidden=model(ix.view(-1,1),hidden)\n",
        "                ix = torch.argmax(Softmax1D(out), dim=1)\n",
        "                generated_sentence.append(self.train_field.vocab.itos[ix])\n",
        "        if method == 'random':\n",
        "            out,hidden=model(prompt.view(-1,1),hidden)\n",
        "            ix = torch.multinomial(Softmax1D(out),1)[len(prompt)-1]\n",
        "            for i in range(sequence_length):\n",
        "                out,hidden=model(ix.view(-1,1),hidden)\n",
        "                ix = torch.multinomial(Softmax1D(out),1)\n",
        "                generated_sentence.append(self.train_field.vocab.itos[ix])\n",
        "        return ''.join(generated_sentence)\n",
        "\n",
        "    def train_model(self, num_epochs : int) -> LSTMModel:\n",
        "        \"\"\"\n",
        "        The function takes in the number of epochs and the model and trains the model for the given\n",
        "        number of epochs\n",
        "        \n",
        "        :param num_epochs: Number of epochs to train for\n",
        "        :return: The model is being returned.\n",
        "        \"\"\"\n",
        "        # vocab_size = \n",
        "        loss_fn = nn.CrossEntropyLoss()\n",
        "        total_steps = 0\n",
        "        loss_plot =[]\n",
        "        perp_plot=[]\n",
        "        for epoch in range(1, num_epochs+1):\n",
        "            cost = 0\n",
        "            num_steps =0\n",
        "            hidden=None\n",
        "            print(\"___________________________________________________________________________\")\n",
        "            print(f\"EPOCH: {epoch}\")\n",
        "            print(f'Total Steps: {total_steps}')\n",
        "            print(\"___________________________________________________________________________\")\n",
        "            for batch in tqdm(self.bptt_iterator):\n",
        "                self.model.train()\n",
        "                self.optimizer.zero_grad()\n",
        "                output, hidden = self.model(batch.text.to(self.device),hidden)\n",
        "                hidden = (hidden[0].detach(), hidden[1].detach())\n",
        "                targets = batch.target\n",
        "                targets = targets.view(targets.shape[0]*targets.shape[1]).to(self.device)\n",
        "                out = output.view(-1, self.model.vocab_size)\n",
        "                loss = loss_fn(out,targets)\n",
        "                cost += loss.item()\n",
        "                num_steps += 1\n",
        "                total_steps+=1\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "            if epoch%10==0:\n",
        "                self.model.eval()\n",
        "                for prompt in self.samples:\n",
        "                    print()\n",
        "                    print('Greedy decoding')\n",
        "                    gen_text = self.predict(self.model, prompt, 100)\n",
        "                    print(f'Sample prompt: {prompt} | generated text: {gen_text}')\n",
        "                    print()\n",
        "                    print('Random decoding')\n",
        "                    gen_text = self.predict(self.model, prompt, 100, method='random')\n",
        "                    print(f'Sample prompt: {prompt} | generated text: {gen_text}')\n",
        "                    print()\n",
        "\n",
        "            perplexity = np.exp(cost/num_steps)\n",
        "            loss_plot.append(cost/num_steps)\n",
        "            perp_plot.append(perplexity)\n",
        "            print(f\"Training Loss: {cost/num_steps}, \\n Training perplexity: {perplexity}\")\n",
        "        _, ax1 = plt.subplots()\n",
        "        _, ax2 = plt.subplots()\n",
        "        ax1.plot(loss_plot,'coral')\n",
        "        ax1.set_xlabel('Epoch')\n",
        "        ax1.set_ylabel('Loss')\n",
        "        ax1.title.set_text('Train Loss Plot')\n",
        "        ax1.legend([\"Train Loss\"])\n",
        "        ax2.plot(perp_plot,'deepskyblue')\n",
        "        ax2.set_xlabel('Epoch')\n",
        "        ax2.set_ylabel('Loss')\n",
        "        ax2.title.set_text('Train Perplexity Plot')\n",
        "        ax2.legend([\"Train Perplexity\"])\n",
        "        plt.show()\n",
        "        return self.model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W20rI4jSGFUx"
      },
      "source": [
        "# Train the fable and the trump models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "0Mcc93DPGFUx",
        "outputId": "f92f2be9-d078-4d9c-dbc6-54c8a23b2218",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on data from: data/books/AesopsFables.txt\n",
            "Fable Analysis\n",
            "Word Count:  5033\n",
            "Line Count:  5033\n",
            "Char Count:  138881\n",
            "Sentence Count:  1880\n",
            "Vocab Count:  108\n",
            "Count:  11\n",
            "___________________________________________________________________________\n",
            "EPOCH: 1\n",
            "Total Steps: 0\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 3.508342244408347, \n",
            " Training perplexity: 33.3928646660972\n",
            "___________________________________________________________________________\n",
            "EPOCH: 2\n",
            "Total Steps: 11\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 2.777178244157271, \n",
            " Training perplexity: 16.073601118460317\n",
            "___________________________________________________________________________\n",
            "EPOCH: 3\n",
            "Total Steps: 22\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 2.413649862462824, \n",
            " Training perplexity: 11.174672822728244\n",
            "___________________________________________________________________________\n",
            "EPOCH: 4\n",
            "Total Steps: 33\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 2.173078927126798, \n",
            " Training perplexity: 8.785291715053017\n",
            "___________________________________________________________________________\n",
            "EPOCH: 5\n",
            "Total Steps: 44\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:06<00:00,  1.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 1.9946836233139038, \n",
            " Training perplexity: 7.349877330178992\n",
            "___________________________________________________________________________\n",
            "EPOCH: 6\n",
            "Total Steps: 55\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:06<00:00,  1.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 1.8573272878473455, \n",
            " Training perplexity: 6.406590895297073\n",
            "___________________________________________________________________________\n",
            "EPOCH: 7\n",
            "Total Steps: 66\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:06<00:00,  1.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 1.7435639121315696, \n",
            " Training perplexity: 5.717684479353002\n",
            "___________________________________________________________________________\n",
            "EPOCH: 8\n",
            "Total Steps: 77\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 1.643246672370217, \n",
            " Training perplexity: 5.1719338580971845\n",
            "___________________________________________________________________________\n",
            "EPOCH: 9\n",
            "Total Steps: 88\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 1.558387203650041, \n",
            " Training perplexity: 4.751152421391351\n",
            "___________________________________________________________________________\n",
            "EPOCH: 10\n",
            "Total Steps: 99\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Greedy decoding\n",
            "Sample prompt: Dogs like best to | generated text: the strong the strong the strong the strong the strong the strong the strong the strong the strong t\n",
            "\n",
            "Random decoding\n",
            "Sample prompt: Dogs like best to | generated text: that younte. Dether,<eos>one and that not onte vaily, but onner sureing the Crane before to mest; I all \n",
            "\n",
            "\n",
            "Greedy decoding\n",
            "Sample prompt: THERE were once some Frogs who lived together | generated text: the strong the strong the strong the strong the strong the strong the strong the strong the strong t\n",
            "\n",
            "Random decoding\n",
            "Sample prompt: THERE were once some Frogs who lived together | generated text:  “I will seom brent these us.<eos><eos><eos><eos><eos><eos>THE WOR'F ANT WA TRLOMA<eos><eos><eos>ONT Fall<eos>his gow that time he went his \n",
            "\n",
            "\n",
            "Greedy decoding\n",
            "Sample prompt: THE WOMAN AND HER HEN | generated text: AND THE FOX<eos><eos><eos>A WOLF and the Fox and the Fox and the Fox and the Fox and the Fox and the Fox and the\n",
            "\n",
            "Random decoding\n",
            "Sample prompt: THE WOMAN AND HER HEN | generated text:  WALE THE HORSO<eos><eos><eos><eos><eos>A THI Criinn on am on with a sell me that<eos>who thisheid. We hose the put the frie\n",
            "\n",
            "Training Loss: 1.4804481267929077, \n",
            " Training perplexity: 4.394914718734514\n",
            "___________________________________________________________________________\n",
            "EPOCH: 11\n",
            "Total Steps: 110\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 1.419391317801042, \n",
            " Training perplexity: 4.134603014918184\n",
            "___________________________________________________________________________\n",
            "EPOCH: 12\n",
            "Total Steps: 121\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 1.357061136852611, \n",
            " Training perplexity: 3.8847597319632077\n",
            "___________________________________________________________________________\n",
            "EPOCH: 13\n",
            "Total Steps: 132\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 1.308378978209062, \n",
            " Training perplexity: 3.7001707906095618\n",
            "___________________________________________________________________________\n",
            "EPOCH: 14\n",
            "Total Steps: 143\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 1.2572523572228171, \n",
            " Training perplexity: 3.5157481839559686\n",
            "___________________________________________________________________________\n",
            "EPOCH: 15\n",
            "Total Steps: 154\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 1.2077831788496538, \n",
            " Training perplexity: 3.346058810766518\n",
            "___________________________________________________________________________\n",
            "EPOCH: 16\n",
            "Total Steps: 165\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 1.1698520617051558, \n",
            " Training perplexity: 3.221516017687662\n",
            "___________________________________________________________________________\n",
            "EPOCH: 17\n",
            "Total Steps: 176\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 1.127450401132757, \n",
            " Training perplexity: 3.0877738708599978\n",
            "___________________________________________________________________________\n",
            "EPOCH: 18\n",
            "Total Steps: 187\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 1.0917246666821567, \n",
            " Training perplexity: 2.9794081299558886\n",
            "___________________________________________________________________________\n",
            "EPOCH: 19\n",
            "Total Steps: 198\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 1.0562111681157893, \n",
            " Training perplexity: 2.8754557059784647\n",
            "___________________________________________________________________________\n",
            "EPOCH: 20\n",
            "Total Steps: 209\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Greedy decoding\n",
            "Sample prompt: Dogs like best to | generated text: her charges of the work of the same carefully against the work of a little Fox who had no companion \n",
            "\n",
            "Random decoding\n",
            "Sample prompt: Dogs like best to | generated text: first the foot. The Foxes good frightened head one good a<eos>twightin,” he had generowned the other Fwa\n",
            "\n",
            "\n",
            "Greedy decoding\n",
            "Sample prompt: THERE were once some Frogs who lived together | generated text: heart the Fox who had no companion when he was not a good price.<eos><eos>“What good let her good found a fe\n",
            "\n",
            "Random decoding\n",
            "Sample prompt: THERE were once some Frogs who lived together | generated text: feven her against him,<eos>but in sight,” said he;, and he felf gound.<eos><eos><eos><eos><eos>THE HEUND AND EACE<eos><eos><eos>THE GODE\n",
            "\n",
            "\n",
            "Greedy decoding\n",
            "Sample prompt: THE WOMAN AND HER HEN | generated text: <eos><eos>A DOG once had a Fox was a part of the Foxes                                                      \n",
            "\n",
            "Random decoding\n",
            "Sample prompt: THE WOMAN AND HER HEN | generated text: <eos><eos>“DOMY Bear Mercury ow against for his Sheener, and all draw his hard the water carrequences and al\n",
            "\n",
            "Training Loss: 1.0224732919172808, \n",
            " Training perplexity: 2.7800621732121886\n",
            "___________________________________________________________________________\n",
            "EPOCH: 21\n",
            "Total Steps: 220\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.9873887571421537, \n",
            " Training perplexity: 2.6842161727847644\n",
            "___________________________________________________________________________\n",
            "EPOCH: 22\n",
            "Total Steps: 231\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.9410923448475924, \n",
            " Training perplexity: 2.5627793287047975\n",
            "___________________________________________________________________________\n",
            "EPOCH: 23\n",
            "Total Steps: 242\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.8962021524255926, \n",
            " Training perplexity: 2.4502796292353857\n",
            "___________________________________________________________________________\n",
            "EPOCH: 24\n",
            "Total Steps: 253\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.8587951280853965, \n",
            " Training perplexity: 2.3603151023870335\n",
            "___________________________________________________________________________\n",
            "EPOCH: 25\n",
            "Total Steps: 264\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.8258946646343578, \n",
            " Training perplexity: 2.2839231968592597\n",
            "___________________________________________________________________________\n",
            "EPOCH: 26\n",
            "Total Steps: 275\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.7945470268076117, \n",
            " Training perplexity: 2.213438141546818\n",
            "___________________________________________________________________________\n",
            "EPOCH: 27\n",
            "Total Steps: 286\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.7577912319790233, \n",
            " Training perplexity: 2.1335584764800486\n",
            "___________________________________________________________________________\n",
            "EPOCH: 28\n",
            "Total Steps: 297\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.7117971236055548, \n",
            " Training perplexity: 2.037649878862861\n",
            "___________________________________________________________________________\n",
            "EPOCH: 29\n",
            "Total Steps: 308\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.6716824228113348, \n",
            " Training perplexity: 1.957527941414482\n",
            "___________________________________________________________________________\n",
            "EPOCH: 30\n",
            "Total Steps: 319\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Greedy decoding\n",
            "Sample prompt: Dogs like best to | generated text: see what it was.<eos><eos>“Oh, I did not know when you have to save you to stop that you have a good dinner.\n",
            "\n",
            "Random decoding\n",
            "Sample prompt: Dogs like best to | generated text: derive caught down to the<eos>high more<eos>beautiful crying that whoever, but it is get outs,<eos>eared awake t\n",
            "\n",
            "\n",
            "Greedy decoding\n",
            "Sample prompt: THERE were once some Frogs who lived together | generated text: to call upon him. Alate your standing through the strong.”<eos><eos>“I am strong and stood for you.”<eos><eos>“It is\n",
            "\n",
            "Random decoding\n",
            "Sample prompt: THERE were once some Frogs who lived together | generated text:  Not her came to inquite a dinner captive, might be turned to<eos>incum for yoe.” But nivery ax, twentay\n",
            "\n",
            "\n",
            "Greedy decoding\n",
            "Sample prompt: THE WOMAN AND HER HEN | generated text: <eos><eos>A DOG once made a company of a thirsty wise caught in the water and stood under the stronger came \n",
            "\n",
            "Random decoding\n",
            "Sample prompt: THE WOMAN AND HER HEN | generated text: <eos><eos>A CITRAVER Ond having been this many large about you wide sweet alone which she covetted, the<eos>mist\n",
            "\n",
            "Training Loss: 0.6447631499984048, \n",
            " Training perplexity: 1.9055356496977358\n",
            "___________________________________________________________________________\n",
            "EPOCH: 31\n",
            "Total Steps: 330\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.6331561045213179, \n",
            " Training perplexity: 1.8835458757841366\n",
            "___________________________________________________________________________\n",
            "EPOCH: 32\n",
            "Total Steps: 341\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.6037972298535433, \n",
            " Training perplexity: 1.8290509574634115\n",
            "___________________________________________________________________________\n",
            "EPOCH: 33\n",
            "Total Steps: 352\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.5545987324281172, \n",
            " Training perplexity: 1.7412421405658882\n",
            "___________________________________________________________________________\n",
            "EPOCH: 34\n",
            "Total Steps: 363\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.5023928609761324, \n",
            " Training perplexity: 1.6526711553670639\n",
            "___________________________________________________________________________\n",
            "EPOCH: 35\n",
            "Total Steps: 374\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.4695057543841275, \n",
            " Training perplexity: 1.5992035984920234\n",
            "___________________________________________________________________________\n",
            "EPOCH: 36\n",
            "Total Steps: 385\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.46129306879910553, \n",
            " Training perplexity: 1.5861236265181167\n",
            "___________________________________________________________________________\n",
            "EPOCH: 37\n",
            "Total Steps: 396\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.4404134750366211, \n",
            " Training perplexity: 1.5533493569303265\n",
            "___________________________________________________________________________\n",
            "EPOCH: 38\n",
            "Total Steps: 407\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.40163053436712787, \n",
            " Training perplexity: 1.4942591532729286\n",
            "___________________________________________________________________________\n",
            "EPOCH: 39\n",
            "Total Steps: 418\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.3745435286651958, \n",
            " Training perplexity: 1.4543274043074081\n",
            "___________________________________________________________________________\n",
            "EPOCH: 40\n",
            "Total Steps: 429\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Greedy decoding\n",
            "Sample prompt: Dogs like best to | generated text: be real. Dashing down to the pattry that<eos>the proposed the Frog from the pond came to the lattle, his\n",
            "\n",
            "Random decoding\n",
            "Sample prompt: Dogs like best to | generated text: elate.<eos><eos>Please check, a try a latter that the Moon made him at last no<eos>  long feel by a lattlem, tha\n",
            "\n",
            "\n",
            "Greedy decoding\n",
            "Sample prompt: THERE were once some Frogs who lived together | generated text:  they came to the latter, the<eos>Crow opened her mouth to say the Frog from the contest of the<eos>animally\n",
            "\n",
            "Random decoding\n",
            "Sample prompt: THERE were once some Frogs who lived together | generated text:  he rain.<eos><eos>5. The leaf Cat came apoly to you help proceed to say: “I be not to look<eos>to my eat a hol!\n",
            "\n",
            "\n",
            "Greedy decoding\n",
            "Sample prompt: THE WOMAN AND HER HEN | generated text: <eos><eos>A PERTAIN man had the hand on a Lion’s Skin                   19<eos>    The Wolf and the Shepherd    \n",
            "\n",
            "Random decoding\n",
            "Sample prompt: THE WOMAN AND HER HEN | generated text: <eos><eos>A PIGEON who was only a Gallage cherford, Project Gutenberg Literary<eos>Archive Foundation ax proclai\n",
            "\n",
            "Training Loss: 0.3383267332207073, \n",
            " Training perplexity: 1.4025987041385066\n",
            "___________________________________________________________________________\n",
            "EPOCH: 41\n",
            "Total Steps: 440\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.3038220541043715, \n",
            " Training perplexity: 1.355027912979518\n",
            "___________________________________________________________________________\n",
            "EPOCH: 42\n",
            "Total Steps: 451\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.2867490879514001, \n",
            " Training perplexity: 1.3320899341257806\n",
            "___________________________________________________________________________\n",
            "EPOCH: 43\n",
            "Total Steps: 462\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.28380563855171204, \n",
            " Training perplexity: 1.3281747596944833\n",
            "___________________________________________________________________________\n",
            "EPOCH: 44\n",
            "Total Steps: 473\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.25537326390093024, \n",
            " Training perplexity: 1.290943393520073\n",
            "___________________________________________________________________________\n",
            "EPOCH: 45\n",
            "Total Steps: 484\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.22225111045620657, \n",
            " Training perplexity: 1.248884946561127\n",
            "___________________________________________________________________________\n",
            "EPOCH: 46\n",
            "Total Steps: 495\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.2091653821143237, \n",
            " Training perplexity: 1.2326488397452804\n",
            "___________________________________________________________________________\n",
            "EPOCH: 47\n",
            "Total Steps: 506\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.20736240663311697, \n",
            " Training perplexity: 1.2304284064052173\n",
            "___________________________________________________________________________\n",
            "EPOCH: 48\n",
            "Total Steps: 517\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.19649037312377582, \n",
            " Training perplexity: 1.2171236037235118\n",
            "___________________________________________________________________________\n",
            "EPOCH: 49\n",
            "Total Steps: 528\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.17305733398957687, \n",
            " Training perplexity: 1.188934269474959\n",
            "___________________________________________________________________________\n",
            "EPOCH: 50\n",
            "Total Steps: 539\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Greedy decoding\n",
            "Sample prompt: Dogs like best to | generated text: earnest and many assisted the Horse, and will come up and said, “Thank<eos>you must expect to suffer by \n",
            "\n",
            "Random decoding\n",
            "Sample prompt: Dogs like best to | generated text: provide a replarch for ene to do. Anow use it means of<eos>why I am courty and restore, he lost in the<eos>s\n",
            "\n",
            "\n",
            "Greedy decoding\n",
            "Sample prompt: THERE were once some Frogs who lived together | generated text: in the world. Let others choose when the Fox was abroad, the Horse asked a Moth<eos>to let a bird go. Wh\n",
            "\n",
            "Random decoding\n",
            "Sample prompt: THERE were once some Frogs who lived together | generated text: as long<eos>enough. You must located in the<eos>  Are and hole as see a dog,<eos>and all the first blew a tree, \n",
            "\n",
            "\n",
            "Greedy decoding\n",
            "Sample prompt: THE WOMAN AND HER HEN | generated text: <eos><eos>A THRIFTY Woman kept a Hen to come and help her eat up the forest.<eos><eos>As they fell groaning the Hawk\n",
            "\n",
            "Random decoding\n",
            "Sample prompt: THE WOMAN AND HER HEN | generated text: <eos><eos>A THURS, bITY, one of the gold was the owner of such a bouse who is neither a<eos>piece of cheese out \n",
            "\n",
            "Training Loss: 0.159687571904876, \n",
            " Training perplexity: 1.173144290493784\n",
            "___________________________________________________________________________\n",
            "EPOCH: 51\n",
            "Total Steps: 550\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.15600216388702393, \n",
            " Training perplexity: 1.1688287323004596\n",
            "___________________________________________________________________________\n",
            "EPOCH: 52\n",
            "Total Steps: 561\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.13591341809792953, \n",
            " Training perplexity: 1.1455827025714824\n",
            "___________________________________________________________________________\n",
            "EPOCH: 53\n",
            "Total Steps: 572\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.11354356733235446, \n",
            " Training perplexity: 1.120240693727845\n",
            "___________________________________________________________________________\n",
            "EPOCH: 54\n",
            "Total Steps: 583\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.09808321500366385, \n",
            " Training perplexity: 1.1030545719796812\n",
            "___________________________________________________________________________\n",
            "EPOCH: 55\n",
            "Total Steps: 594\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.08203717625953934, \n",
            " Training perplexity: 1.0854961637665532\n",
            "___________________________________________________________________________\n",
            "EPOCH: 56\n",
            "Total Steps: 605\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.06834347783164545, \n",
            " Training perplexity: 1.070733018380484\n",
            "___________________________________________________________________________\n",
            "EPOCH: 57\n",
            "Total Steps: 616\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.059456522491845215, \n",
            " Training perplexity: 1.061259619052734\n",
            "___________________________________________________________________________\n",
            "EPOCH: 58\n",
            "Total Steps: 627\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.051107781515880066, \n",
            " Training perplexity: 1.052436320352398\n",
            "___________________________________________________________________________\n",
            "EPOCH: 59\n",
            "Total Steps: 638\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.04737241633913734, \n",
            " Training perplexity: 1.0485124195343503\n",
            "___________________________________________________________________________\n",
            "EPOCH: 60\n",
            "Total Steps: 649\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Greedy decoding\n",
            "Sample prompt: Dogs like best to | generated text: eat at home, and he<eos>peased to the ice.<eos><eos>No great harm was done; the Fox could easily remedy it. It h\n",
            "\n",
            "Random decoding\n",
            "Sample prompt: Dogs like best to | generated text: eat attempted trademark that the<eos>Poor Mannerstopped downling in the well. “I will return the cock, s\n",
            "\n",
            "\n",
            "Greedy decoding\n",
            "Sample prompt: THERE were once some Frogs who lived together | generated text: <eos><eos>They renewed the Wolf took up the head Frog, and<eos>the Horse was fed with chaff and whatever he migh\n",
            "\n",
            "Random decoding\n",
            "Sample prompt: THERE were once some Frogs who lived together | generated text: in perfect meat in the<eos>world.”<eos><eos>“And so would we,” said the hens. “Nothing can do us good if it is n\n",
            "\n",
            "\n",
            "Greedy decoding\n",
            "Sample prompt: THE WOMAN AND HER HEN | generated text: <eos><eos>A WOMAN had a Hen that laid an egg every day. The eggs were large, and<eos>sold for a good price. The \n",
            "\n",
            "Random decoding\n",
            "Sample prompt: THE WOMAN AND HER HEN | generated text: <eos><eos>A SWARREN once can a dog as to will have sitting there was water,<eos>but that it was even to eat it u\n",
            "\n",
            "Training Loss: 0.04181466658007015, \n",
            " Training perplexity: 1.0427012134602023\n",
            "___________________________________________________________________________\n",
            "EPOCH: 61\n",
            "Total Steps: 660\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.03873975642702796, \n",
            " Training perplexity: 1.0394999252714885\n",
            "___________________________________________________________________________\n",
            "EPOCH: 62\n",
            "Total Steps: 671\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.033054154704917564, \n",
            " Training perplexity: 1.0336065123813662\n",
            "___________________________________________________________________________\n",
            "EPOCH: 63\n",
            "Total Steps: 682\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.03115555406971411, \n",
            " Training perplexity: 1.0316459681346133\n",
            "___________________________________________________________________________\n",
            "EPOCH: 64\n",
            "Total Steps: 693\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.029927278276194225, \n",
            " Training perplexity: 1.0303796002481913\n",
            "___________________________________________________________________________\n",
            "EPOCH: 65\n",
            "Total Steps: 704\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.029017436572096565, \n",
            " Training perplexity: 1.0294425442677813\n",
            "___________________________________________________________________________\n",
            "EPOCH: 66\n",
            "Total Steps: 715\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.027289053255861454, \n",
            " Training perplexity: 1.0276648096951877\n",
            "___________________________________________________________________________\n",
            "EPOCH: 67\n",
            "Total Steps: 726\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.025603933767838913, \n",
            " Training perplexity: 1.025934529970703\n",
            "___________________________________________________________________________\n",
            "EPOCH: 68\n",
            "Total Steps: 737\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.02528189512139017, \n",
            " Training perplexity: 1.0256041925968815\n",
            "___________________________________________________________________________\n",
            "EPOCH: 69\n",
            "Total Steps: 748\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.0259749579497359, \n",
            " Training perplexity: 1.026315247113631\n",
            "___________________________________________________________________________\n",
            "EPOCH: 70\n",
            "Total Steps: 759\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Greedy decoding\n",
            "Sample prompt: Dogs like best to | generated text: advise.<eos><eos>The Man looked up gratefully, but, growing faint with sudden heat, he<eos>quickly flung aside h\n",
            "\n",
            "Random decoding\n",
            "Sample prompt: Dogs like best to | generated text: adge.<eos><eos>He who saw his whick haw are grain and was sure to and amused himself beside it, in a quiet, \n",
            "\n",
            "\n",
            "Greedy decoding\n",
            "Sample prompt: THERE were once some Frogs who lived together | generated text:  in all abore, dispecided with him.<eos><eos><eos><eos><eos>THE DOG AND HIS SHADOW<eos><eos><eos>A DOG had stolen a piece of meat ou\n",
            "\n",
            "Random decoding\n",
            "Sample prompt: THERE were once some Frogs who lived together | generated text:  if you came against the air in head wanted. “Oh, Mother,” they<eos>creatures had no protection from suc\n",
            "\n",
            "\n",
            "Greedy decoding\n",
            "Sample prompt: THE WOMAN AND HER HEN | generated text: <eos><eos>A THRIFTY Woman kept a Hen that could be depended on to lay an egg<eos>every morning. The watchful Wom\n",
            "\n",
            "Random decoding\n",
            "Sample prompt: THE WOMAN AND HER HEN | generated text: <eos><eos>A THRIFTY Woman kept a Hen that could be<eos>defind in a while, and in came a Frog, and taken preserve\n",
            "\n",
            "Training Loss: 0.026828447526151485, \n",
            " Training perplexity: 1.0271915703923549\n",
            "___________________________________________________________________________\n",
            "EPOCH: 71\n",
            "Total Steps: 770\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.02584523724561388, \n",
            " Training perplexity: 1.026182121411891\n",
            "___________________________________________________________________________\n",
            "EPOCH: 72\n",
            "Total Steps: 781\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.02514085021208633, \n",
            " Training perplexity: 1.0254595465475893\n",
            "___________________________________________________________________________\n",
            "EPOCH: 73\n",
            "Total Steps: 792\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.023857568136670372, \n",
            " Training perplexity: 1.0241444367013652\n",
            "___________________________________________________________________________\n",
            "EPOCH: 74\n",
            "Total Steps: 803\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.021806363693692467, \n",
            " Training perplexity: 1.0220458601231557\n",
            "___________________________________________________________________________\n",
            "EPOCH: 75\n",
            "Total Steps: 814\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.019778105006976562, \n",
            " Training perplexity: 1.019974987571695\n",
            "___________________________________________________________________________\n",
            "EPOCH: 76\n",
            "Total Steps: 825\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.01869116435674104, \n",
            " Training perplexity: 1.018866937596851\n",
            "___________________________________________________________________________\n",
            "EPOCH: 77\n",
            "Total Steps: 836\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.016825695522129536, \n",
            " Training perplexity: 1.0169680447914973\n",
            "___________________________________________________________________________\n",
            "EPOCH: 78\n",
            "Total Steps: 847\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.016264133409342983, \n",
            " Training perplexity: 1.0163971143890729\n",
            "___________________________________________________________________________\n",
            "EPOCH: 79\n",
            "Total Steps: 858\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.015260969965972683, \n",
            " Training perplexity: 1.015378013207959\n",
            "___________________________________________________________________________\n",
            "EPOCH: 80\n",
            "Total Steps: 869\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Greedy decoding\n",
            "Sample prompt: Dogs like best to | generated text: eat at home,<eos>and his wood as necessary in replacement copy in doing and wisping him. “If you really \n",
            "\n",
            "Random decoding\n",
            "Sample prompt: Dogs like best to | generated text: eat at home, and<eos>he was sold to a farmer, who made him drag heavy loads.<eos><eos>Since he had not been trai\n",
            "\n",
            "\n",
            "Greedy decoding\n",
            "Sample prompt: THERE were once some Frogs who lived together | generated text: in the Introduction.<eos><eos>No occasion has been found to change in this edition the style of<eos>presentation\n",
            "\n",
            "Random decoding\n",
            "Sample prompt: THERE were once some Frogs who lived together | generated text: in the IS<eos>That so life of Nermins, the Cock thought he was a mousect, and are<eos>redistributing Project\n",
            "\n",
            "\n",
            "Greedy decoding\n",
            "Sample prompt: THE WOMAN AND HER HEN | generated text: <eos><eos>A THRIFTY Woman kept a Hen that could be depended on to lay an egg<eos>every morning. The watchful Wom\n",
            "\n",
            "Random decoding\n",
            "Sample prompt: THE WOMAN AND HER HEN | generated text: <eos><eos>A THRIFTY Woman kept a Hen that could be depended on to lay an egg<eos>every morning. The watchful Wom\n",
            "\n",
            "Training Loss: 0.014586071483790874, \n",
            " Training perplexity: 1.014692967322221\n",
            "___________________________________________________________________________\n",
            "EPOCH: 81\n",
            "Total Steps: 880\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.01372996387495236, \n",
            " Training perplexity: 1.0138246526906767\n",
            "___________________________________________________________________________\n",
            "EPOCH: 82\n",
            "Total Steps: 891\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.01264099378816106, \n",
            " Training perplexity: 1.0127212288774496\n",
            "___________________________________________________________________________\n",
            "EPOCH: 83\n",
            "Total Steps: 902\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.01306751590560783, \n",
            " Training perplexity: 1.0131532690111602\n",
            "___________________________________________________________________________\n",
            "EPOCH: 84\n",
            "Total Steps: 913\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.012879453345455906, \n",
            " Training perplexity: 1.0129627507288033\n",
            "___________________________________________________________________________\n",
            "EPOCH: 85\n",
            "Total Steps: 924\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.011536436240104113, \n",
            " Training perplexity: 1.0116032375565585\n",
            "___________________________________________________________________________\n",
            "EPOCH: 86\n",
            "Total Steps: 935\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.0102853103202175, \n",
            " Training perplexity: 1.0103383859347257\n",
            "___________________________________________________________________________\n",
            "EPOCH: 87\n",
            "Total Steps: 946\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.009667126927524805, \n",
            " Training perplexity: 1.009714004534531\n",
            "___________________________________________________________________________\n",
            "EPOCH: 88\n",
            "Total Steps: 957\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.009548871269957586, \n",
            " Training perplexity: 1.0095946072008142\n",
            "___________________________________________________________________________\n",
            "EPOCH: 89\n",
            "Total Steps: 968\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.010110962627963587, \n",
            " Training perplexity: 1.0101622511235375\n",
            "___________________________________________________________________________\n",
            "EPOCH: 90\n",
            "Total Steps: 979\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Greedy decoding\n",
            "Sample prompt: Dogs like best to | generated text: eat at home, and he went<eos>trick and again, and put the poor broken Tree.<eos><eos>“O Reed,” said the Tree, “h\n",
            "\n",
            "Random decoding\n",
            "Sample prompt: Dogs like best to | generated text: lay that the Fox could never reach her, in<eos>her nest high in the pine tree, flew away with the little\n",
            "\n",
            "\n",
            "Greedy decoding\n",
            "Sample prompt: THERE were once some Frogs who lived together | generated text:  if you will be as well<eos>as it will not to let you go; for no death is too bad for one who is ready t\n",
            "\n",
            "Random decoding\n",
            "Sample prompt: THERE were once some Frogs who lived together | generated text: in the great field. The<eos>Ants were busy all the time gathering a store of grain to lay by for<eos>winter \n",
            "\n",
            "\n",
            "Greedy decoding\n",
            "Sample prompt: THE WOMAN AND HER HEN | generated text: <eos><eos>A THRIFTY Woman kept a Hen that could be depended on to lay an egg<eos>every morning. The watchful Wom\n",
            "\n",
            "Random decoding\n",
            "Sample prompt: THE WOMAN AND HER HEN | generated text: <eos><eos>A THRIFTY Woman kept a Hen that could be depended on to lay an egg<eos>every morning. The watchful Wom\n",
            "\n",
            "Training Loss: 0.010604203255339102, \n",
            " Training perplexity: 1.010660627085565\n",
            "___________________________________________________________________________\n",
            "EPOCH: 91\n",
            "Total Steps: 990\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.011015584438361904, \n",
            " Training perplexity: 1.0110764793810099\n",
            "___________________________________________________________________________\n",
            "EPOCH: 92\n",
            "Total Steps: 1001\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.011052487968382511, \n",
            " Training perplexity: 1.0111137923607059\n",
            "___________________________________________________________________________\n",
            "EPOCH: 93\n",
            "Total Steps: 1012\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.012178348885341124, \n",
            " Training perplexity: 1.0122528069278007\n",
            "___________________________________________________________________________\n",
            "EPOCH: 94\n",
            "Total Steps: 1023\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.012556520714001223, \n",
            " Training perplexity: 1.0126356848151152\n",
            "___________________________________________________________________________\n",
            "EPOCH: 95\n",
            "Total Steps: 1034\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.013426354832269928, \n",
            " Training perplexity: 1.01351689308009\n",
            "___________________________________________________________________________\n",
            "EPOCH: 96\n",
            "Total Steps: 1045\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.014626885764300823, \n",
            " Training perplexity: 1.0147343821307728\n",
            "___________________________________________________________________________\n",
            "EPOCH: 97\n",
            "Total Steps: 1056\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.014507814987816593, \n",
            " Training perplexity: 1.0146135641130576\n",
            "___________________________________________________________________________\n",
            "EPOCH: 98\n",
            "Total Steps: 1067\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.012411546300758015, \n",
            " Training perplexity: 1.012488889191942\n",
            "___________________________________________________________________________\n",
            "EPOCH: 99\n",
            "Total Steps: 1078\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.009825472423637455, \n",
            " Training perplexity: 1.0098739008586082\n",
            "___________________________________________________________________________\n",
            "EPOCH: 100\n",
            "Total Steps: 1089\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Greedy decoding\n",
            "Sample prompt: Dogs like best to | generated text: eat at home,<eos>and his vines were presently destroyed. The simple<eos>fellow learned, when it was too late\n",
            "\n",
            "Random decoding\n",
            "Sample prompt: Dogs like best to | generated text: eat at home,<eos>and finding that her high wis taken by stated that it was<eos>subssight to eat it up. Again\n",
            "\n",
            "\n",
            "Greedy decoding\n",
            "Sample prompt: THERE were once some Frogs who lived together | generated text:  if you will be as desperite to instruct and to be instructed,<eos>he traveled through many countries, a\n",
            "\n",
            "Random decoding\n",
            "Sample prompt: THERE were once some Frogs who lived together | generated text:  if you will be<eos>as to be well.”<eos><eos>“Alas,” said the Father, “if you wish for fine weather, and your si\n",
            "\n",
            "\n",
            "Greedy decoding\n",
            "Sample prompt: THE WOMAN AND HER HEN | generated text: <eos><eos>A THRIFTY Woman kept a Hen that could be depended on to lay an egg<eos>every morning. The watchful Wom\n",
            "\n",
            "Random decoding\n",
            "Sample prompt: THE WOMAN AND HER HEN | generated text: <eos><eos>A TWO man eft them all the attract and tre frost, a council<eos>was called accordingly, to consider th\n",
            "\n",
            "Training Loss: 0.008624717381528833, \n",
            " Training perplexity: 1.008662017413446\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXwV9b3/8dcnCyHsGqJACAYq4oIsGkFwKWJt3apd9LoVpdpLtbbY2mqrba167+1Vf11dqsW96HWvFRfqvlbFBkUUQUWLEtxClK2sST6/P74TOMQEEpLJJGfez8djHpmZM+ecz3D0vM8s3+/X3B0REUmvnKQLEBGRZCkIRERSTkEgIpJyCgIRkZRTEIiIpJyCQEQk5RQEkipmNtPMTkm6jrZiZhea2S1J1yGdm4JAOjwzW5Ux1ZnZmozlk1ryWu5+mLvfvI11LDKzL23Lc1vDzG4ys/XR/n5qZo+a2a7b8DqJ1C8dn4JAOjx371E/Ae8DX81Yd2v9dmaWl1yVsbss2v+BwCfATcmWI9lEQSCdlplNMLNKM/upmX0E3Ghm25nZA2ZWZWafRfMDM57zlJl9J5qfbGbPmdlvom3/ZWaHbUMdBWb2BzP7IJr+YGYF0WN9oxqWRb/mnzWznOixn5rZEjNbaWZvmtnBW3svd18N/B8wvIlajjKzedH7PWVmu0XrpwODgPujI4tzW7qfkr0UBNLZ9QO2B3YCphD+m74xWh4ErAGu3MLzxwJvAn2By4DrzcxaWMPPgX2BUcBIYAzwi+ixHwOVQDGwI3A+4GY2DPg+sI+79wS+Aiza2huZWQ/gJOCVRh7bBbgN+GH0fg8Rvvi7uPskNj+auqyF+yhZTEEgnV0d8Ct3X+fua9y92t3vcffV7r4S+B/gi1t4/nvufq271wI3A/0JX9gtcRJwsbt/4u5VwEXApOixDdFr7uTuG9z9WQ8dfNUCBcDuZpbv7ovc/Z0tvMdPzGwZsBDoAUxuZJvjgAfd/VF33wD8BigExrdwfyRlFATS2VW5+9r6BTPrZmZ/NrP3zGwF8AzQx8xym3j+R/Uz0WkXCF+0LTEAeC9j+b1oHcD/I3x5P2Jm75rZz6L3Wkj45X4h8ImZ3W5mA2jab9y9j7v3c/ejmgiNzepw9zpgMVDSwv2RlFEQSGfXsPvcHwPDgLHu3gs4MFrf0tM9LfEB4VRUvUHROtx9pbv/2N2HAEcBZ9dfC3D3/3P3/aPnOnBpW9YRneIqBZZEq9TVsDRKQSDZpifhusAyM9se+FUbv36+mXXNmPII5+V/YWbFZtYXuAC4BcDMjjSznaMv5eWEU0J1ZjbMzCZGF5XXRjXXtbK2O4EjzOxgM8snhOI64Pno8Y+BIa18D8lCCgLJNn8gnBdfCrwI/L2NX/8hwpd2/XQh8N9ABTAXeA14OVoHMBR4DFgFvAD8yd2fJFwfuCSq8yNgB+C81hTm7m8C3wKuiF73q4SLw+ujTf6XEFjLzOwnrXkvyS6mgWlERNJNRwQiIimnIBARSTkFgYhIyikIRERSrtN10tW3b18vKytLugwRkU5l9uzZS929uLHHOl0QlJWVUVFRkXQZIiKdipm919RjOjUkIpJyCgIRkZRTEIiIpFynu0YgItllw4YNVFZWsnbt2q1vLFvVtWtXBg4cSH5+frOfoyAQkURVVlbSs2dPysrKaPmYQJLJ3amurqayspLBgwc3+3k6NSQiiVq7di1FRUUKgTZgZhQVFbX46Cq2IIi66H3JzF6NxlC9qJFtJkdjy86Jpu/EVY+IdFwKgbazLf+WcZ4aWgdMdPdVUd/oz5nZTHd/scF2d7j792OsI/j4PXj9ORj3VejWK/a3ExHpLGI7IvBgVbSYH03J9Xld/QE8ezcsr06sBBHpeKqrqxk1ahSjRo2iX79+lJSUbFxev379Fp9bUVHB1KlTW/R+ZWVlLF26tDUlt7lYLxZH48TOBnYGrnL3WY1s9k0zOxB4C/iRuy9u5HWmAFMABg0atG3FdOsZ/q5ZuW3PF5GsVFRUxJw5cwC48MIL6dGjBz/5yaZxe2pqasjLa/yrsry8nPLy8napM06xXix291p3HwUMBMaY2fAGm9wPlLn7COBR4OYmXmeau5e7e3lxcaNdZWxdYRQEqxUEIrJlkydP5vTTT2fs2LGce+65vPTSS4wbN47Ro0czfvx43nzzTQCeeuopjjzySCCEyKmnnsqECRMYMmQIl19+ebPfb9GiRUycOJERI0Zw8MEH8/777wNw1113MXz4cEaOHMmBB4bht+fNm8eYMWMYNWoUI0aM4O233271/rbL7aPuvszMngQOBV7PWJ95nuY64LLYitARgUjHN/N6+Ohfbfua/QbDYae1+GmVlZU8//zz5ObmsmLFCp599lny8vJ47LHHOP/887nnnns+95wFCxbw5JNPsnLlSoYNG8YZZ5zRrPv5f/CDH3DKKadwyimncMMNNzB16lT+9re/cfHFF/Pwww9TUlLCsmXLALjmmms466yzOOmkk1i/fj21tbUt3reG4rxrqNjM+kTzhcAhwIIG2/TPWDwKmB9XPToiEJGWOPbYY8nNzQVg+fLlHHvssQwfPpwf/ehHzJs3r9HnHHHEERQUFNC3b1922GEHPv7442a91wsvvMCJJ54IwKRJk3juuecA2G+//Zg8eTLXXnvtxi/8cePG8etf/5pLL72U9957j8LCwtbuaqxHBP2Bm6PrBDnAne7+gJldDFS4+wxgqpkdBdQAnwKTY6smLx+6dNURgUhHtg2/3OPSvXv3jfO//OUvOeigg7j33ntZtGgREyZMaPQ5BQUFG+dzc3OpqalpVQ3XXHMNs2bN4sEHH2Tvvfdm9uzZnHjiiYwdO5YHH3yQww8/nD//+c9MnDixVe8TWxC4+1xgdCPrL8iYPw84L64aPqewJ6xe0W5vJyLZYfny5ZSUlABw0003tfnrjx8/nttvv51JkyZx6623csABBwDwzjvvMHbsWMaOHcvMmTNZvHgxy5cvZ8iQIUydOpX333+fuXPntjoI0tWyuFsvnRoSkRY799xzOe+88xg9enSrf+UDjBgxgoEDBzJw4EDOPvtsrrjiCm688UZGjBjB9OnT+eMf/wjAOeecw5577snw4cMZP348I0eO5M4772T48OGMGjWK119/nZNPPrnV9Zh7crf2b4vy8nLf5oFppl8Ea/8N/xnfNWkRaZn58+ez2267JV1GVmns39TMZrt7o/e6puuIoLCnjghERBpIVxB066mLxSIiDaQrCAp7hlNDbXDfrYi0nc52iroj25Z/y3QFQX2jsrWrtrydiLSbrl27Ul1drTBoA/XjEXTt2rVFz0vXwDSZjcq69062FhEBYODAgVRWVlJVVZV0KVmhfoSylkhXEKibCZEOJz8/v0WjaUnbS9epIXUzISLyOekKAh0RiIh8TrqCQEcEIiKfk64gKCiEnFwdEYiIZEhXEJipdbGISAPpCgJQ62IRkQbSFwTqilpEZDPpC4JuOjUkIpIpnUGwRl1MiIjUS18Q1F8sVr8mIiJAGoOgW0+oq4H1a5OuRESkQ4gtCMysq5m9ZGavmtk8M7uokW0KzOwOM1toZrPMrCyuejZSozIRkc3EeUSwDpjo7iOBUcChZrZvg21OAz5z952B3wOXxlhPoG4mREQ2E1sQeFB/VTY/mhqemD8auDmavxs42MwsrpoAHRGIiDQQ6zUCM8s1sznAJ8Cj7j6rwSYlwGIAd68BlgNFjbzOFDOrMLOKVvdZriMCEZHNxBoE7l7r7qOAgcAYMxu+ja8zzd3L3b28uLi4dUXpiEBEZDPtcteQuy8DngQObfDQEqAUwMzygN5AdazFFOqIQEQkU5x3DRWbWZ9ovhA4BFjQYLMZwCnR/DHAEx73wKW5uVDQTUcEIiKROIeq7A/cbGa5hMC5090fMLOLgQp3nwFcD0w3s4XAp8DxMdaziTqeExHZKLYgcPe5wOhG1l+QMb8WODauGpqkrqhFRDZKX8ti0BGBiEiGdAaBjghERDZKZxB005gEIiL10hkEhT1h/Rqo2ZB0JSIiiUtnEHTrFf5qXAIRkbQGgRqViYjUS2kQREcE/16ebB0iIh1AOoNgu37h76cfJluHiEgHkM4g6F0EuflQ/UHSlYiIJC6dQZCTC0X9FQQiIqQ1CACKBsBSBYGISLqD4LOPoLY26UpERBKV7iCoq4VlnyRdiYhIolIcBCXhb/WSZOsQEUlYioNgQPirC8YiknLpDYJuPaFrDwWBiKReeoPADPoOgKU6NSQi6ZbeIIBweqharYtFJN0UBCurYd2apCsREUlMbEFgZqVm9qSZvWFm88zsrEa2mWBmy81sTjRd0Nhrxab+ziH1OSQiKRbb4PVADfBjd3/ZzHoCs83sUXd/o8F2z7r7kTHW0bTMO4f6D0mkBBGRpMV2RODuH7r7y9H8SmA+UBLX+22T7fuHv7pzSERSrF2uEZhZGTAamNXIw+PM7FUzm2lmezTx/ClmVmFmFVVVVW1XWJcC6F2sO4dEJNViDwIz6wHcA/zQ3RuOGP8ysJO7jwSuAP7W2Gu4+zR3L3f38uLi4rYtsGiAjghEJNViDQIzyyeEwK3u/teGj7v7CndfFc0/BOSbWd84a/qc+u6o3dv1bUVEOoo47xoy4Hpgvrv/rolt+kXbYWZjonqq46qpUUUlsG61hq0UkdSK866h/YBJwGtmNidadz4wCMDdrwGOAc4wsxpgDXC8ezv/NK+/c2jpEujRp13fWkSkI4gtCNz9OcC2ss2VwJVx1dAsOwwKfz/6F5Q1eq1aRCSrpbtlMUDvvtCrLyx+M+lKREQSoSAAKN0VFi9IugoRkUQoCABKh8GKpbB8adKViIi0OwUBhCMC0OkhEUklBQFAvzLI66LTQyKSSgoCgNw8KNlZQSAiqaQgqFe6a7iFdP26pCsREWlXCoJ6pbtCXS18sDDpSkRE2pWCoN7AYeGvTg+JSMooCOp17xW6m9CdQyKSMgqCTKW7QuWb6olURFJFQZCpdBisXqExjEUkVRQEmeoblr3XcFhlEZHspSDIVFwKPYvgrYqkKxERaTcKgkxmMGwfeGcObFifdDUiIu1CQdDQsH1gwzr412tJVyIi0i4UBA0N3hO6dIU3X0q6EhGRdqEgaCgvH74wGt78J9TVJV2NiEjsFASN2XUMrPoMPnwn6UpERGIXWxCYWamZPWlmb5jZPDM7q5FtzMwuN7OFZjbXzPaKq54WGboXWE44KhARyXJxHhHUAD92992BfYEzzWz3BtscBgyNpinA1THW03zdesGgXRUEIpIKsQWBu3/o7i9H8yuB+UBJg82OBv7iwYtAHzPrH1dNLTJsDHy8CD77JOlKRERi1S7XCMysDBgNzGrwUAmwOGO5ks+HBWY2xcwqzKyiqqoqrjI3N2yf8HfBi+3zfiIiCYk9CMysB3AP8EN3X7Etr+Hu09y93N3Li4uL27bAphQNgAE7wyuPqxM6EclqsQaBmeUTQuBWd/9rI5ssAUozlgdG6zqGvQ+BT96HyreSrkREJDZx3jVkwPXAfHf/XRObzQBOju4e2hdY7u4dp+vP4QdAfleY/UjSlYiIxCbOI4L9gEnARDObE02Hm9npZnZ6tM1DwLvAQuBa4Hsx1tNyBYWw5/4w7x+w9t9JVyMiEou8uF7Y3Z8DbCvbOHBmXDW0ib2/DC8/Bq89C/scmnQ1IiJtrllHBGbW3cxyovldzOyo6Px/9huwM+xYBrMfTboSEZFYNPfU0DNAVzMrAR4hnPK5Ka6iOhSzcFTw0bvwgbqcEJHs09wgMHdfDXwD+JO7HwvsEV9ZHcyIAyG/AGY9mHQlIiJtrtlBYGbjgJOA+m/D3HhK6oC6doe9vgSvPQPL1NJYRLJLc4Pgh8B5wL3uPs/MhgBPxldWBzT+a4DBP/6WdCUiIm2qWUHg7k+7+1Hufml00Xipu0+NubaOpXdfGDkh3EG08rOkqxERaTPNvWvo/8ysl5l1B14H3jCzc+ItrQPa/+tQVwsv3p90JSIibaa5p4Z2j/oJ+howExhMuHMoXYoGwB7j4Z8zYc2qpKsREWkTzQ2C/KjdwNeAGe6+AUhnT2z7fxPWr4UXH0i6EhGRNtHcIPgzsAjoDjxjZjsB29STaKfXrwx22xdeuA9WLUu6GhGRVmvuxeLL3b3E3Q+PBpF5Dzgo5to6roO/BRvWwzN3JV2JiEirNfdicW8z+1394DBm9lvC0UE69S0J7QoqHobqjtNZqojItmjuqaEbgJXAf0TTCuDGuIrqFCYcB7l58MStSVciItIqzQ2CL7j7r9z93Wi6CBgSZ2EdXs/tYdxRoYvqJW8nXY2IyDZrbhCsMbP96xfMbD9gTTwldSL7fR269YK/3wB1dUlXIyKyTZobBKcDV5nZIjNbBFwJfDe2qjqLgkL48mRYvCBcLxAR6YSae9fQq+4+EhgBjHD30cDEWCvrLEZOgCEj4bHpsHxp0tWIiLRYi4aqdPcVUQtjgLNjqKfzMYOvngFeBw/+GTyd7exEpPNqzZjFWxyGMlW22xEOOgHeqggXj0VEOpHWBIF++mYae2QY1vKha9U7qYh0KlsMAjNbaWYrGplWAgO28twbzOwTM3u9iccnmNlyM5sTTRe0Yj+Sl5sLX58a+iGacZVOEYlIp7HFIHD3nu7eq5Gpp7vnbeW1bwIO3co2z7r7qGi6uCWFd0jFpXDIyfD2bN1FJCKdRmtODW2Ruz8DfBrX63dY+xwGXxgFj9wES5ckXY2IyFbFFgTNNM7MXjWzmWa2R1MbmdmU+n6Oqqqq2rO+lsvJgaO/D7n5cPfvYJ3a3YlIx5ZkELwM7BS1T7gCaHIwYHef5u7l7l5eXFzcbgVus15F8I2z4ONFcNdvoLYm6YpERJqUWBBEbRJWRfMPEQa/6ZtUPW1ul3I48ruw8GW4/2pdPBaRDmtrF3xjY2b9gI/d3c1sDCGUqpOqJxZ7fxlWfApP3xGOEiaemHRFIiKfE1sQmNltwASgr5lVAr8C8gHc/RrgGOAMM6shdGB3vHsW/myecBysqA6D2PQuhr0PSboiEZHNxBYE7n7CVh6/ktB5XXYzC6eIVlbDA9eEI4OheyVdlYjIRknfNZQOuXlw7Dmw405w1/+DD/+VdEUiIhspCNpLQSGc+Avo2gNu/S/4SGEgIh2DgqA99doeJl0Q2hrc+At4d27SFYmIKAjaXXEpnHZJuFZwy3/Ba88mXZGIpJyCIAm9+8Kp/wulu8A9v4eXZiZdkYikmIIgKYXd4Vu/Cg3PHpoGz96TdEUiklIKgiTld4HjzoU9D4THb4FH/6IWyCLS7hJrWSyR3Dz4+lnhrqJ/3AurV8KRp4fxDURE2oGCoCPIyYEjvgvdeoUWyKtXwDFnQ35B0pWJSAro1FBHYRb6IjrsP+HNf8L0i2DVsqSrEpEUUBB0NGMPD0cDSxbCn86C+bOSrkhEspyCoCMavj9897fQqy/ccQncd6UGuBGR2CgIOqodSuE7l8ABx8CcJ+G6n2roSxGJhYKgI8vLh4NPgkm/gn8vh2nnwPwXk65KRLKMgqAzGDIinCoqHgh3XBq6s167OumqRCRLKAg6i9594dv/A+OOhtmPhgvJb7+cdFUikgUUBJ1JXj58ZTKc+mvo0jV0Z33v5aERmojINlIQdEalw+D034ULyXOfhqumwhsvJF2ViHRSCoLOqv5C8pTfQM/t4c7L4PZLYPnSpCsTkU4mtiAwsxvM7BMze72Jx83MLjezhWY218w0kO+26D8Y/vNSOPhbsPAVuOoH8ML9UFubdGUi0knEeURwE3DoFh4/DBgaTVOAq2OsJbvl5sEB34QzL4dBu8PDN4R2BxoOU0SaIbYgcPdngE+3sMnRwF88eBHoY2b946onFbbbEU76BRz7E1ixNLQ7ePwW2LA+6cpEpANL8hpBCbA4Y7kyWvc5ZjbFzCrMrKKqqqpdiuu0zGCP/eDMK2DEF8OAN9efByuqk65MRDqoTnGx2N2nuXu5u5cXFxcnXU7n0K0nfO0HcML58OkHcO258OG7SVclIh1QkkGwBCjNWB4YrZO2NGyfMD6y5cAN58MC9WYqIptLMghmACdHdw/tCyx39w8TrCd79SsLdxYVl8Ltl4bTRRoSU0QisY1QZma3AROAvmZWCfwKyAdw92uAh4DDgYXAauDbcdUihLYG3/7v0KX147fAJ+/DUd/TKGgiEl8QuPsJW3ncgTPjen9pRH4BfPNs2GEneOJWqFoM3/gh7DAo6cpEJEGd4mKxtCEzOPCYcBF5RTX8+Sfw/H1QpwZoImmlIEirYfvA9/4IO4+GR26Cm34JH7+XdFUikgAFQZr16APH/wyO/kE4TXTN2fDwjRoWUyRlYrtGIJ2EGYyeCLuUw+PT4YUZ8Nqz8KVJoUFajn4riGQ7/V8uQfdecNSZcNol0KsI/nY5XP8zqHwr6cpEJGYKAtlc6TD4zqXwtamhS+vrfgZ/vwE2rEu6MhGJiU4Nyefl5MCog2C3feGx6fDi/fD27BAOpcOSrk5E2piOCKRpBYVwxBQ4+SKo2RC6qHhpZtJViUgbUxDI1g0ZAWf8AYbuBQ9Ng5nXaeAbkSyiIJDm6dot3Gq671dh1oNw269hzaqkqxKRNqAgkObLyYVDT4UjT4d3Xw3tDt5fkHRVItJKCgJpufKvwKm/Dl1b3/jz0JupThWJdFoKAtk2A3eB038b7ix6/Ba48kx4+TGorUm6MhFpIfNO1i99eXm5V1RUJF2G1HOHtyrg6Tvhg4XQuxiG7g0lQ0NY9C0JrZdFJFFmNtvdyxt7TO0IpHXMQgd2u5TD2y+HC8mvPQMVfw+P77Q7fOlktT8Q6cAUBNI2zGCXvcNUVwfVS2DhHHjur6Grit3GhQvNvfsmXamINKBrBNL2cnLCsJjjvgpT/wQTjoeFr8B1P1VX1yIdkIJA4lVQCBOOg+9cEpZv/Dm890ayNYnIZhQE0j523AlO+1/o3gemXwQLXkq6IhGJxBoEZnaomb1pZgvN7GeNPD7ZzKrMbE40fSfOeiRhfXYI7Q923AnuuBRefy7pikSEGIPAzHKBq4DDgN2BE8xs90Y2vcPdR0XTdXHVIx1E916hE7tBu8I9v4dXnki6IpHUi/OIYAyw0N3fdff1wO3A0TG+n3QWBYVw0gUweE+47wp46o7Qu6mIJCLOICgBFmcsV0brGvqmmc01s7vNrLSxFzKzKWZWYWYVVVVVcdQq7a1LAZxwPgw/AJ66Ha7+EbzzatJViaRS0u0I7gduc/d1ZvZd4GZgYsON3H0aMA1Cy+L2LVFik98FjjkbRn4RHroOpl8I/YZA8UAoGgClu8Lg4aGzOxGJTZxBsATI/IU/MFq3kbtXZyxeB1wWYz3SUQ3dG763J8x6AN6dC+/PD62TIXRZMeogGP0l6FOcbJ0iWSrOIPgnMNTMBhMC4HjgxMwNzKy/u38YLR4FzI+xHunI8rvA/t8IE8D6tfDWbHjlcXj6Lnj+vtAyea9D1HeRSBuLLQjcvcbMvg88DOQCN7j7PDO7GKhw9xnAVDM7CqgBPgUmx1WPdDJdusLw/cL02ccw409w/9WhP6OjvgfdeiVdoUjWUO+j0jnU1cGL98Njt4TR0vb7GuxzWAgMEdmqLfU+qpbF0jnk5MD4o2HKZdD/C/DoX+AP3w2njDQGgkirKAikc+k3GCZdELqr6P8FeOSm0JndR4uSrkyk01IQSOdUumsIhP84F1ZUw7Rz1DBNZBsl3Y5ApHV2Hwc77QEzrw0N0954Hr76PQ2EI9ICOiKQzq97Lzjmx6Gl8trVcP158MA18ME7YShNEdkiHRFI9hi2D5QNhyduhZdmQsXD0KtvGDWt5/bQpRC69YRhY8KdRyICKAgk2xQUwmHfgQP/A96qgAWzYO4zsH7Npm0Ke4aGa2MOg/yC5GoV6SDUjkDSobY2hEFVJTx9J7zzSjhK+NIkGPFFtVaWrLeldgQKAkmnRa+HtghL3oaddocjvgs7DEq6KpHYKAhEGlNXB688Bo9OD0cLZcNDKAzaHXoXQV4XyMuHrj1CgzaRTmxLQaBrBJJeOTmw95dh17Hwj3vDeAhP3g40+HFU0A36DwkN2IbuFQbU0akkySIKApHuveHLk8P8mlWw+E1YsxJq1sOGdbD0A/jwHXjpIXjhPiguhbFHwp4HhIvTIp2cgkAkU2GPcLtpYzash3nPwYsPwgNXw0PTYMAXQoO2foPD3UiF3aHPjqFtg0gnoSAQaa78LjBqIow8CBYvCLenLpoHL8yAutpN21kO7DwaRk4IbRbyuyRWskhzKAhEWsoMBu0WJgiD6CyrgrWrNp1amvsU3P1b6No9hEf5V6BvY0N2iyRPdw2JxKGuFv71Orz8GMx/ISyXDYddymHnvcK4zLrgLO1It4+KJGnlZ+E21deeharFYV3v4jBW8y7lMHi4WjhL7BQEIh3FsqrQqvmt2fDuXNiwNrRXKB0GZXtC2R6w407hlJJIG1I7ApGOok9xaLuw95fD2AmL5sHCl0NL5ydvY2Mbhp7bh9tUiwaEawtFJdCjT7irqbCHhuiUNhVrEJjZocAfCYPXX+fulzR4vAD4C7A3UA0c5+6L4qxJpMPIy4edR4UJYPXKcDdSVWU4hVS1GF59avMO8+p16RrCouf2IRgKuoWjiG69oNf20LMorM/rEu5aysuH3DzIzYec3GjK0XUKAWIMAjPLBa4CDgEqgX+a2Qx3fyNjs9OAz9x9ZzM7HrgUOC6umkQ6tG49Q1faw/bZtM4dVn0G1R/C6hWhodvqlfDv5bDy0zAtXQLrVsPaf4c7mFoiJy+ERF7+pi418rqE0DALt8IaoTuOujrwunDhu642LOfkZARL7ubLuXlhyusSroHkZ/zNK4C8vPD+ubkhoPK7bHrvnJzw3pmvnZsbrct4LLf+8bxN8+7RVBf20SxM9ftaX2cc3MMY2vX/VtT/29VummprNv2tZzmhtvyCMHUpCHW2kziPCMYAC939XQAzux04GsgMgqOBC6P5u4Erzcy8s124EImL2aZf/s2xfl0UENVhkJ6a9aEhXM36TV8+9V9E9cs1G8LjNRs2zdfWhC8yJ12rALQAAAbySURBVPzdeASRs+kL13IyvuRqNoVF/WuvXwu10WtuWBdNUWvt+i/JpGQGVWa4WGZA+KYvdK/bPGAahg1s/uXfFvK6hCO/+qO5nDzY+xAYf3TbvUf9W7X5K25SAizOWK4Exja1jbvXmNlyoAhYmrmRmU0BpgAMGqQeIkWa1KUAivqHqSOrD6DMcNqwblMI1UVftg1/SXvmkUldg1/Y0XaZRzKwKcwy36t2Q1RDDXhtxhc+m5608XVyNp1Gqw+KnIzQqD+9Vn/UsTEoM7bPzdsUphtP0eUQioxCpT60N6wLIbp+bTgtuLHmmnCdKAad4mKxu08DpkG4ayjhckSktep/jUuHEGffukuA0ozlgdG6RrcxszygN+GisYiItJM4g+CfwFAzG2xmXYDjgRkNtpkBnBLNHwM8oesDIiLtK7Zjs+ic//eBhwm3j97g7vPM7GKgwt1nANcD081sIfApISxERKQdxXqSzt0fAh5qsO6CjPm1wLFx1iAiIlum8fdERFJOQSAiknIKAhGRlFMQiIikXKfrhtrMqoD3tvHpfWnQajkl0rjfadxnSOd+p3GfoeX7vZO7Fzf2QKcLgtYws4qm+uPOZmnc7zTuM6Rzv9O4z9C2+61TQyIiKacgEBFJubQFwbSkC0hIGvc7jfsM6dzvNO4ztOF+p+oagYiIfF7ajghERKQBBYGISMqlJgjM7FAze9PMFprZz5KuJw5mVmpmT5rZG2Y2z8zOitZvb2aPmtnb0d/tkq41DmaWa2avmNkD0fJgM5sVfeZ3RN2hZw0z62Nmd5vZAjObb2bj0vBZm9mPov++Xzez28ysazZ+1mZ2g5l9YmavZ6xr9PO14PJo/+ea2V4tea9UBIGZ5QJXAYcBuwMnmNnuyVYVixrgx+6+O7AvcGa0nz8DHnf3ocDj0XI2OguYn7F8KfB7d98Z+Aw4LZGq4vNH4O/uviswkrDvWf1Zm1kJMBUod/fhhC7ujyc7P+ubgEMbrGvq8z0MGBpNU4CrW/JGqQgCYAyw0N3fdff1wO1A248AnTB3/9DdX47mVxK+GEoI+3pztNnNwNeSqTA+ZjYQOAK4Llo2YCJwd7RJVu23mfUGDiSM6YG7r3f3ZaTgsyZ0n18YjWrYDfiQLPys3f0ZwjgtmZr6fI8G/uLBi0AfM2v2wNVpCYISYHHGcmW0LmuZWRkwGpgF7OjuH0YPfQTsmFBZcfoDcC5QFy0XAcvcvSZazrbPfDBQBdwYnQ67zsy6k+WftbsvAX4DvE8IgOXAbLL7s87U1Ofbqu+4tARBqphZD+Ae4IfuviLzsWgo0Ky6Z9jMjgQ+cffZSdfSjvKAvYCr3X008G8anAbK0s96O8Kv38HAAKA7nz99kgpt+fmmJQiWAKUZywOjdVnHzPIJIXCru/81Wv1x/WFi9PeTpOqLyX7AUWa2iHDabyLh/Hmf6PQBZN9nXglUuvusaPluQjBk+2f9JeBf7l7l7huAvxI+/2z+rDM19fm26jsuLUHwT2BodGdBF8LFpRkJ19TmovPi1wPz3f13GQ/NAE6J5k8B7mvv2uLk7ue5+0B3LyN8tk+4+0nAk8Ax0WZZtd/u/hGw2MyGRasOBt4gyz9rwimhfc2sW/Tfe/1+Z+1n3UBTn+8M4OTo7qF9geUZp5C2zt1TMQGHA28B7wA/T7qemPZxf8Kh4lxgTjQdTjhf/jjwNvAYsH3Stcb4bzABeCCaHwK8BCwE7gIKkq6vjfd1FFARfd5/A7ZLw2cNXAQsAF4HpgMF2fhZA7cRroNsIBwBntbU5wsY4c7Id4DXCHdVNfu91MWEiEjKpeXUkIiINEFBICKScgoCEZGUUxCIiKScgkBEJOUUBCINmFmtmc3JmNqs4zYzK8vsTVKkI8jb+iYiqbPG3UclXYRIe9ERgUgzmdkiM7vMzF4zs5fMbOdofZmZPRH1A/+4mQ2K1u9oZvea2avRND56qVwzuzbqU/8RMytMbKdEUBCINKawwamh4zIeW+7uewJXEno8BbgCuNndRwC3ApdH6y8Hnnb3kYR+gOZF64cCV7n7HsAy4Jsx74/IFqllsUgDZrbK3Xs0sn4RMNHd34069/vI3YvMbCnQ3903ROs/dPe+ZlYFDHT3dRmvUQY86mFgEczsp0C+u/93/Hsm0jgdEYi0jDcx3xLrMuZr0bU6SZiCQKRljsv4+0I0/zyh11OAk4Bno/nHgTNg43jKvdurSJGW0C8Rkc8rNLM5Gct/d/f6W0i3M7O5hF/1J0TrfkAYKewcwqhh347WnwVMM7PTCL/8zyD0JinSoegagUgzRdcIyt19adK1iLQlnRoSEUk5HRGIiKScjghERFJOQSAiknIKAhGRlFMQiIiknIJARCTl/j/keXauuZwBAAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "fable_samples = ['Dogs like best to', 'THERE were once some Frogs who lived together', 'THE WOMAN AND HER HEN']\n",
        "get_fables()\n",
        "PATH = book_path\n",
        "trainer = Trainer(model_parameters = model_parameters, path = PATH, bptt_len = BPTT_LEN, samples = fable_samples)\n",
        "print(f\"Training on data from: {PATH}\")\n",
        "print(\"Fable Analysis\")\n",
        "counter(PATH)\n",
        "print(\"Vocab Count: \", len(trainer.train_field.vocab))\n",
        "print(\"Count: \", len(trainer.bptt_iterator))\n",
        "fable_model = trainer.train_model(num_epochs=100)\n",
        "torch.save(fable_model.state_dict(), 'fable_model.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "pSfdOw1FGFUy",
        "outputId": "96df195d-4e2b-44b2-fcd0-12dd798ff3c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Count:  1785\n",
            "Line Count:  1785\n",
            "Char Count:  212573\n",
            "Sentence Count:  4852\n",
            "Vocab Count:  86\n",
            "Count:  16\n",
            "___________________________________________________________________________\n",
            "EPOCH: 1\n",
            "Total Steps: 0\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 3.2578169256448746, \n",
            " Training perplexity: 25.992731094493536\n",
            "___________________________________________________________________________\n",
            "EPOCH: 2\n",
            "Total Steps: 16\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 2.4094294607639313, \n",
            " Training perplexity: 11.12761059517039\n",
            "___________________________________________________________________________\n",
            "EPOCH: 3\n",
            "Total Steps: 32\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 2.009411871433258, \n",
            " Training perplexity: 7.4589292476944316\n",
            "___________________________________________________________________________\n",
            "EPOCH: 4\n",
            "Total Steps: 48\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 1.7257963865995407, \n",
            " Training perplexity: 5.616992546522555\n",
            "___________________________________________________________________________\n",
            "EPOCH: 5\n",
            "Total Steps: 64\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 1.5247340947389603, \n",
            " Training perplexity: 4.5939218588931885\n",
            "___________________________________________________________________________\n",
            "EPOCH: 6\n",
            "Total Steps: 80\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 1.3823185488581657, \n",
            " Training perplexity: 3.984128323263662\n",
            "___________________________________________________________________________\n",
            "EPOCH: 7\n",
            "Total Steps: 96\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 1.2769896686077118, \n",
            " Training perplexity: 3.5858289283018823\n",
            "___________________________________________________________________________\n",
            "EPOCH: 8\n",
            "Total Steps: 112\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 1.1995025724172592, \n",
            " Training perplexity: 3.3184658156883926\n",
            "___________________________________________________________________________\n",
            "EPOCH: 9\n",
            "Total Steps: 128\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 1.1358468160033226, \n",
            " Training perplexity: 3.1138092502724577\n",
            "___________________________________________________________________________\n",
            "EPOCH: 10\n",
            "Total Steps: 144\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Greedy decoding\n",
            "Sample prompt: Good morning America | generated text:  people that we have to the morning that we have the states of the morning that we want to get the f\n",
            "\n",
            "Random decoding\n",
            "Sample prompt: Good morning America | generated text:  and he was wrong power religious can cover one, we will end from the subpracess very sincely, the l\n",
            "\n",
            "\n",
            "Greedy decoding\n",
            "Sample prompt: Very good | generated text: and we will be the first that we have the states of the morning that we want to get the father we wi\n",
            "\n",
            "Random decoding\n",
            "Sample prompt: Very good | generated text:  I’m renoight from the second watch the very, woke North God 1n, $0,000, U87. It’s a vote the are ar\n",
            "\n",
            "\n",
            "Greedy decoding\n",
            "Sample prompt: Donald Trump: | generated text: (01:01:05)<eos>We have the states of the morning that we want to get the father we will be the first tha\n",
            "\n",
            "Random decoding\n",
            "Sample prompt: Donald Trump: | generated text: (447:01)<eos>Cour you that anyway, I all happening in to me, “on who assuhrouss, “NoV, that’d again, the\n",
            "\n",
            "Training Loss: 1.0791170969605446, \n",
            " Training perplexity: 2.9420808319169955\n",
            "___________________________________________________________________________\n",
            "EPOCH: 11\n",
            "Total Steps: 160\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 1.0281106904149055, \n",
            " Training perplexity: 2.7957787502114844\n",
            "___________________________________________________________________________\n",
            "EPOCH: 12\n",
            "Total Steps: 176\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.9814706332981586, \n",
            " Training perplexity: 2.6683775627059982\n",
            "___________________________________________________________________________\n",
            "EPOCH: 13\n",
            "Total Steps: 192\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.9433689564466476, \n",
            " Training perplexity: 2.568620428285025\n",
            "___________________________________________________________________________\n",
            "EPOCH: 14\n",
            "Total Steps: 208\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.9153436496853828, \n",
            " Training perplexity: 2.4976334153800357\n",
            "___________________________________________________________________________\n",
            "EPOCH: 15\n",
            "Total Steps: 224\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.8782270848751068, \n",
            " Training perplexity: 2.40662917262868\n",
            "___________________________________________________________________________\n",
            "EPOCH: 16\n",
            "Total Steps: 240\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.8397681787610054, \n",
            " Training perplexity: 2.3158300559557983\n",
            "___________________________________________________________________________\n",
            "EPOCH: 17\n",
            "Total Steps: 256\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.810456495732069, \n",
            " Training perplexity: 2.248934381333039\n",
            "___________________________________________________________________________\n",
            "EPOCH: 18\n",
            "Total Steps: 272\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.7744087092578411, \n",
            " Training perplexity: 2.1693090555252152\n",
            "___________________________________________________________________________\n",
            "EPOCH: 19\n",
            "Total Steps: 288\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.7438667565584183, \n",
            " Training perplexity: 2.1040556761175755\n",
            "___________________________________________________________________________\n",
            "EPOCH: 20\n",
            "Total Steps: 304\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Greedy decoding\n",
            "Sample prompt: Good morning America | generated text: were from the most in the world. And the next morning and we will make America great again. Thank yo\n",
            "\n",
            "Random decoding\n",
            "Sample prompt: Good morning America | generated text: safe, confidence, from I mean, it’s true. Where’s Peterre’s going an ofther strents down now. They d\n",
            "\n",
            "\n",
            "Greedy decoding\n",
            "Sample prompt: Very good | generated text: reasons we’re going to win four more years of President Donald Trump in the history of our country a\n",
            "\n",
            "Random decoding\n",
            "Sample prompt: Very good | generated text: rating, and strung, your drugs and all the insleepy, just mic how the great America and plague on th\n",
            "\n",
            "\n",
            "Greedy decoding\n",
            "Sample prompt: Donald Trump: | generated text: (01:01:08)<eos>I was so badly, they were treated by the way, we’re going to win four more years of Presi\n",
            "\n",
            "Random decoding\n",
            "Sample prompt: Donald Trump: | generated text: (17:00)<eos>She protects want to do it. Because of univerers. You never happened if I am safety going to\n",
            "\n",
            "Training Loss: 0.7141623385250568, \n",
            " Training perplexity: 2.042475062806158\n",
            "___________________________________________________________________________\n",
            "EPOCH: 21\n",
            "Total Steps: 320\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.6806976646184921, \n",
            " Training perplexity: 1.975255317375785\n",
            "___________________________________________________________________________\n",
            "EPOCH: 22\n",
            "Total Steps: 336\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.6546691060066223, \n",
            " Training perplexity: 1.9245056046620739\n",
            "___________________________________________________________________________\n",
            "EPOCH: 23\n",
            "Total Steps: 352\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.62198306620121, \n",
            " Training perplexity: 1.8626180767991363\n",
            "___________________________________________________________________________\n",
            "EPOCH: 24\n",
            "Total Steps: 368\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.590885829180479, \n",
            " Training perplexity: 1.805587148975347\n",
            "___________________________________________________________________________\n",
            "EPOCH: 25\n",
            "Total Steps: 384\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.560091707855463, \n",
            " Training perplexity: 1.7508330580788138\n",
            "___________________________________________________________________________\n",
            "EPOCH: 26\n",
            "Total Steps: 400\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.5390584357082844, \n",
            " Training perplexity: 1.714391891817613\n",
            "___________________________________________________________________________\n",
            "EPOCH: 27\n",
            "Total Steps: 416\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.5118969734758139, \n",
            " Training perplexity: 1.6684532063498765\n",
            "___________________________________________________________________________\n",
            "EPOCH: 28\n",
            "Total Steps: 432\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.47373875603079796, \n",
            " Training perplexity: 1.6059873777026048\n",
            "___________________________________________________________________________\n",
            "EPOCH: 29\n",
            "Total Steps: 448\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.4455697275698185, \n",
            " Training perplexity: 1.5613795034271363\n",
            "___________________________________________________________________________\n",
            "EPOCH: 30\n",
            "Total Steps: 464\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Greedy decoding\n",
            "Sample prompt: Good morning America | generated text: into the manufacturing superpower of the world, all the way down. But he’s a great group of people a\n",
            "\n",
            "Random decoding\n",
            "Sample prompt: Good morning America | generated text:  we are off and a half. I’ll never have been will leaving to the United States will be all achoised \n",
            "\n",
            "\n",
            "Greedy decoding\n",
            "Sample prompt: Very good | generated text:  I want to talk about it. I don’t know. I don’t know. I don’t know. I don’t know. I don’t know. I do\n",
            "\n",
            "Random decoding\n",
            "Sample prompt: Very good | generated text: in jais that fracking? What a good guy. I never even here. I haday that always does that all happene\n",
            "\n",
            "\n",
            "Greedy decoding\n",
            "Sample prompt: Donald Trump: | generated text: (01:21:03)<eos>… all of them, all of them. I don’t want to give him the money at that bad things are hap\n",
            "\n",
            "Random decoding\n",
            "Sample prompt: Donald Trump: | generated text: Young a job you all despred available. I’m place it was will wipe out that walk off. They think here\n",
            "\n",
            "Training Loss: 0.42657019942998886, \n",
            " Training perplexity: 1.5319940682784383\n",
            "___________________________________________________________________________\n",
            "EPOCH: 31\n",
            "Total Steps: 480\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.4107594005763531, \n",
            " Training perplexity: 1.5079624980001285\n",
            "___________________________________________________________________________\n",
            "EPOCH: 32\n",
            "Total Steps: 496\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.3806584980338812, \n",
            " Training perplexity: 1.4632478180686164\n",
            "___________________________________________________________________________\n",
            "EPOCH: 33\n",
            "Total Steps: 512\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.34832954593002796, \n",
            " Training perplexity: 1.4166990402241273\n",
            "___________________________________________________________________________\n",
            "EPOCH: 34\n",
            "Total Steps: 528\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.32185858860611916, \n",
            " Training perplexity: 1.3796896583239369\n",
            "___________________________________________________________________________\n",
            "EPOCH: 35\n",
            "Total Steps: 544\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.300707483664155, \n",
            " Training perplexity: 1.3508141485354919\n",
            "___________________________________________________________________________\n",
            "EPOCH: 36\n",
            "Total Steps: 560\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.28182265162467957, \n",
            " Training perplexity: 1.3255436161330274\n",
            "___________________________________________________________________________\n",
            "EPOCH: 37\n",
            "Total Steps: 576\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.2580297365784645, \n",
            " Training perplexity: 1.2943773084043517\n",
            "___________________________________________________________________________\n",
            "EPOCH: 38\n",
            "Total Steps: 592\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.24233974236994982, \n",
            " Training perplexity: 1.274227028196186\n",
            "___________________________________________________________________________\n",
            "EPOCH: 39\n",
            "Total Steps: 608\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.22786302212625742, \n",
            " Training perplexity: 1.2559132813186147\n",
            "___________________________________________________________________________\n",
            "EPOCH: 40\n",
            "Total Steps: 624\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Greedy decoding\n",
            "Sample prompt: Good morning America | generated text: s by far the highest. And we will end our reliance on China once and for all. Nobody knew it was str\n",
            "\n",
            "Random decoding\n",
            "Sample prompt: Good morning America | generated text:  blood and traveled big did with farmers, I delligive it the worst Cornat and Coast Guard, 14 years \n",
            "\n",
            "\n",
            "Greedy decoding\n",
            "Sample prompt: Very good | generated text: places with that for 52 years, I got off the plane, I meant Social Security as well all of them. We \n",
            "\n",
            "Random decoding\n",
            "Sample prompt: Very good | generated text: open up. Look at him on that if I didn’t supposed to pro-American values. This will not be the only \n",
            "\n",
            "\n",
            "Greedy decoding\n",
            "Sample prompt: Donald Trump: | generated text: (23:54)<eos>In one order to restore the ones dealing with Russia. What a job she did. Ronna McDaniel. Wh\n",
            "\n",
            "Random decoding\n",
            "Sample prompt: Donald Trump: | generated text: (23:05)<eos>But on the problem itself. And he never come back and you could possibly imagine. This is no\n",
            "\n",
            "Training Loss: 0.20524835586547852, \n",
            " Training perplexity: 1.2278299658734808\n",
            "___________________________________________________________________________\n",
            "EPOCH: 41\n",
            "Total Steps: 640\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.19096513744443655, \n",
            " Training perplexity: 1.2104172531069803\n",
            "___________________________________________________________________________\n",
            "EPOCH: 42\n",
            "Total Steps: 656\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.1789677869528532, \n",
            " Training perplexity: 1.1959822173158001\n",
            "___________________________________________________________________________\n",
            "EPOCH: 43\n",
            "Total Steps: 672\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.15867909509688616, \n",
            " Training perplexity: 1.1719617980427206\n",
            "___________________________________________________________________________\n",
            "EPOCH: 44\n",
            "Total Steps: 688\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.1409433730877936, \n",
            " Training perplexity: 1.151359448208339\n",
            "___________________________________________________________________________\n",
            "EPOCH: 45\n",
            "Total Steps: 704\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.12725271470844746, \n",
            " Training perplexity: 1.1357039906217028\n",
            "___________________________________________________________________________\n",
            "EPOCH: 46\n",
            "Total Steps: 720\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.11732342140749097, \n",
            " Training perplexity: 1.124483052777251\n",
            "___________________________________________________________________________\n",
            "EPOCH: 47\n",
            "Total Steps: 736\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.10840653395280242, \n",
            " Training perplexity: 1.1145007356917411\n",
            "___________________________________________________________________________\n",
            "EPOCH: 48\n",
            "Total Steps: 752\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.09654319705441594, \n",
            " Training perplexity: 1.1013571555012285\n",
            "___________________________________________________________________________\n",
            "EPOCH: 49\n",
            "Total Steps: 768\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.08759342366829515, \n",
            " Training perplexity: 1.0915442357462208\n",
            "___________________________________________________________________________\n",
            "EPOCH: 50\n",
            "Total Steps: 784\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Greedy decoding\n",
            "Sample prompt: Good morning America | generated text:  blood and treasure in endless foreign wars in countries that most of you have never even heard of, \n",
            "\n",
            "Random decoding\n",
            "Sample prompt: Good morning America | generated text:  blood and treasure in endless foreign, ribs the care they know I have a great … She’s just a beauti\n",
            "\n",
            "\n",
            "Greedy decoding\n",
            "Sample prompt: Very good | generated text:  I’ll tell you, they understand the disease. It’s a terrible thing. Should never have been allowed t\n",
            "\n",
            "Random decoding\n",
            "Sample prompt: Very good | generated text: <eos><eos>Donald Trump: (02:05:35)<eos>This election comes down to a simple choice, you know what I kid Pennsylv\n",
            "\n",
            "\n",
            "Greedy decoding\n",
            "Sample prompt: Donald Trump: | generated text: (02:21:34)<eos>State GOP Chair, Laura Cox. Laura? Good job. Are we going to win? Otherwise, we will fire\n",
            "\n",
            "Random decoding\n",
            "Sample prompt: Donald Trump: | generated text: (02:17:39)<eos>Thank you very much.<eos><eos>Crowd: (01:38:24)<eos>We love you. We love you. We love you.<eos><eos>Donald Tr\n",
            "\n",
            "Training Loss: 0.07831385033205152, \n",
            " Training perplexity: 1.081462022627455\n",
            "___________________________________________________________________________\n",
            "EPOCH: 51\n",
            "Total Steps: 800\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.0691246862988919, \n",
            " Training perplexity: 1.071569810892744\n",
            "___________________________________________________________________________\n",
            "EPOCH: 52\n",
            "Total Steps: 816\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.059541318099945784, \n",
            " Training perplexity: 1.061349613022977\n",
            "___________________________________________________________________________\n",
            "EPOCH: 53\n",
            "Total Steps: 832\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.05194299388676882, \n",
            " Training perplexity: 1.0533156953680556\n",
            "___________________________________________________________________________\n",
            "EPOCH: 54\n",
            "Total Steps: 848\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.04671594360843301, \n",
            " Training perplexity: 1.0478243256052828\n",
            "___________________________________________________________________________\n",
            "EPOCH: 55\n",
            "Total Steps: 864\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.04117722134105861, \n",
            " Training perplexity: 1.0420367603347105\n",
            "___________________________________________________________________________\n",
            "EPOCH: 56\n",
            "Total Steps: 880\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.03727008099667728, \n",
            " Training perplexity: 1.037973319853485\n",
            "___________________________________________________________________________\n",
            "EPOCH: 57\n",
            "Total Steps: 896\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.03325510828290135, \n",
            " Training perplexity: 1.0338142401793797\n",
            "___________________________________________________________________________\n",
            "EPOCH: 58\n",
            "Total Steps: 912\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.03014323429670185, \n",
            " Training perplexity: 1.030602140954911\n",
            "___________________________________________________________________________\n",
            "EPOCH: 59\n",
            "Total Steps: 928\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.026480044587515295, \n",
            " Training perplexity: 1.0268337561660712\n",
            "___________________________________________________________________________\n",
            "EPOCH: 60\n",
            "Total Steps: 944\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Greedy decoding\n",
            "Sample prompt: Good morning America | generated text:  blood and treasure in endless ridiculous foreign wars in countries you’ve never even heard of for t\n",
            "\n",
            "Random decoding\n",
            "Sample prompt: Good morning America | generated text:  blood and treasure in endless foreign wars in countries that most of you have never even heard of, \n",
            "\n",
            "\n",
            "Greedy decoding\n",
            "Sample prompt: Very good | generated text: Ronatives leave. Can you hear it back there by the way?<eos><eos>Audience: (03:33)<eos>No!<eos><eos>President Donald J. \n",
            "\n",
            "Random decoding\n",
            "Sample prompt: Very good | generated text: like that.<eos>President Donald J. Trump: (01:10:03)<eos>For years, you had a president who apologized for A\n",
            "\n",
            "\n",
            "Greedy decoding\n",
            "Sample prompt: Donald Trump: | generated text: (01:29:31)<eos>It’s really amazing. And I think we’re winning. I think they’re willing to spend thousand\n",
            "\n",
            "Random decoding\n",
            "Sample prompt: Donald Trump: | generated text: (02:21:32)<eos>Thank you very much.<eos><eos>Crowd: (38:06)<eos>Everyone been a campaign, and I hear they believe pr\n",
            "\n",
            "Training Loss: 0.023297938867472112, \n",
            " Training perplexity: 1.0235714558420845\n",
            "___________________________________________________________________________\n",
            "EPOCH: 61\n",
            "Total Steps: 960\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.020102631067857146, \n",
            " Training perplexity: 1.0203060497528555\n",
            "___________________________________________________________________________\n",
            "EPOCH: 62\n",
            "Total Steps: 976\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.017792362603358924, \n",
            " Training perplexity: 1.017951589626678\n",
            "___________________________________________________________________________\n",
            "EPOCH: 63\n",
            "Total Steps: 992\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.015489634301047772, \n",
            " Training perplexity: 1.0156102204939497\n",
            "___________________________________________________________________________\n",
            "EPOCH: 64\n",
            "Total Steps: 1008\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.014666255156043917, \n",
            " Training perplexity: 1.0147743323925817\n",
            "___________________________________________________________________________\n",
            "EPOCH: 65\n",
            "Total Steps: 1024\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.013846954505424947, \n",
            " Training perplexity: 1.0139432676142657\n",
            "___________________________________________________________________________\n",
            "EPOCH: 66\n",
            "Total Steps: 1040\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.013380645017605275, \n",
            " Training perplexity: 1.0134705664695463\n",
            "___________________________________________________________________________\n",
            "EPOCH: 67\n",
            "Total Steps: 1056\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.013257571961730719, \n",
            " Training perplexity: 1.0133458432250846\n",
            "___________________________________________________________________________\n",
            "EPOCH: 68\n",
            "Total Steps: 1072\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.01344575872644782, \n",
            " Training perplexity: 1.0135365594454322\n",
            "___________________________________________________________________________\n",
            "EPOCH: 69\n",
            "Total Steps: 1088\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.01261363277444616, \n",
            " Training perplexity: 1.0126935201770877\n",
            "___________________________________________________________________________\n",
            "EPOCH: 70\n",
            "Total Steps: 1104\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Greedy decoding\n",
            "Sample prompt: Good morning America | generated text:  blood and treasure in endless foreign, ridiculous wars. Countries you’ve never even heard of. In 20\n",
            "\n",
            "Random decoding\n",
            "Sample prompt: Good morning America | generated text:  blood and treasure in endless foreign, ridiculous wars. Countries you’ve never even heard of. In 20\n",
            "\n",
            "\n",
            "Greedy decoding\n",
            "Sample prompt: Very good | generated text: relationships in different parts of the world. In some we help. We don’t have to, though. Now we don\n",
            "\n",
            "Random decoding\n",
            "Sample prompt: Very good | generated text:  Oh, let them people are tough. You saw that for 55 years, this is the turn a you go into one thing \n",
            "\n",
            "\n",
            "Greedy decoding\n",
            "Sample prompt: Donald Trump: | generated text: (25:15)<eos>And you know, I don’t have the luxury of staying in a basement. I’m president of the United \n",
            "\n",
            "Random decoding\n",
            "Sample prompt: Donald Trump: | generated text: (02:21:53)<eos>No, I think we’re going to have a tremendous victory in all of these States they’re takin\n",
            "\n",
            "Training Loss: 0.011500746360979974, \n",
            " Training perplexity: 1.0115671342035544\n",
            "___________________________________________________________________________\n",
            "EPOCH: 71\n",
            "Total Steps: 1120\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.010111163428518921, \n",
            " Training perplexity: 1.010162453964699\n",
            "___________________________________________________________________________\n",
            "EPOCH: 72\n",
            "Total Steps: 1136\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.008856766973622143, \n",
            " Training perplexity: 1.008896104181966\n",
            "___________________________________________________________________________\n",
            "EPOCH: 73\n",
            "Total Steps: 1152\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.007930648047477007, \n",
            " Training perplexity: 1.0079621789350444\n",
            "___________________________________________________________________________\n",
            "EPOCH: 74\n",
            "Total Steps: 1168\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.007190521893789992, \n",
            " Training perplexity: 1.0072164357705395\n",
            "___________________________________________________________________________\n",
            "EPOCH: 75\n",
            "Total Steps: 1184\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.006615919468458742, \n",
            " Training perplexity: 1.0066378530071611\n",
            "___________________________________________________________________________\n",
            "EPOCH: 76\n",
            "Total Steps: 1200\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.006336192338494584, \n",
            " Training perplexity: 1.0063563084692846\n",
            "___________________________________________________________________________\n",
            "EPOCH: 77\n",
            "Total Steps: 1216\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.006018774030962959, \n",
            " Training perplexity: 1.0060369232451167\n",
            "___________________________________________________________________________\n",
            "EPOCH: 78\n",
            "Total Steps: 1232\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.005674635962350294, \n",
            " Training perplexity: 1.0056907672075497\n",
            "___________________________________________________________________________\n",
            "EPOCH: 79\n",
            "Total Steps: 1248\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.0053970458975527436, \n",
            " Training perplexity: 1.0054116361861059\n",
            "___________________________________________________________________________\n",
            "EPOCH: 80\n",
            "Total Steps: 1264\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Greedy decoding\n",
            "Sample prompt: Good morning America | generated text:  blood and treasure in endless foreign wars in countries that most of you have never even heard of, \n",
            "\n",
            "Random decoding\n",
            "Sample prompt: Good morning America | generated text:  blood and treasure in endless foreign, ridiculous wars. Countries you’ve never even heard of. In 20\n",
            "\n",
            "\n",
            "Greedy decoding\n",
            "Sample prompt: Very good | generated text: relationships in different parts of the world. In some we help. We don’t have to, though. Now we don\n",
            "\n",
            "Random decoding\n",
            "Sample prompt: Very good | generated text: news for you. 99.99, okay, you know what that means? That means you’re in good shape. That’s what th\n",
            "\n",
            "\n",
            "Greedy decoding\n",
            "Sample prompt: Donald Trump: | generated text: (14:17)<eos>The doctor told me, “Sir, your son has tested positive.” I see him like 12 seconds later, “D\n",
            "\n",
            "Random decoding\n",
            "Sample prompt: Donald Trump: | generated text: (15:12)<eos>Can you imagine? You know, I have a lot of my kids here tonight. Could you imagine if my kid\n",
            "\n",
            "Training Loss: 0.005091257073218003, \n",
            " Training perplexity: 1.0051042395455279\n",
            "___________________________________________________________________________\n",
            "EPOCH: 81\n",
            "Total Steps: 1280\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.004778042115503922, \n",
            " Training perplexity: 1.0047894751606705\n",
            "___________________________________________________________________________\n",
            "EPOCH: 82\n",
            "Total Steps: 1296\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.004659781901864335, \n",
            " Training perplexity: 1.004670655568629\n",
            "___________________________________________________________________________\n",
            "EPOCH: 83\n",
            "Total Steps: 1312\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.004477897979086265, \n",
            " Training perplexity: 1.0044879387458239\n",
            "___________________________________________________________________________\n",
            "EPOCH: 84\n",
            "Total Steps: 1328\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.0041682685987325385, \n",
            " Training perplexity: 1.0041769679131147\n",
            "___________________________________________________________________________\n",
            "EPOCH: 85\n",
            "Total Steps: 1344\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.003840215562377125, \n",
            " Training perplexity: 1.003847598638002\n",
            "___________________________________________________________________________\n",
            "EPOCH: 86\n",
            "Total Steps: 1360\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.003731542528839782, \n",
            " Training perplexity: 1.0037385134016679\n",
            "___________________________________________________________________________\n",
            "EPOCH: 87\n",
            "Total Steps: 1376\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.003549839064362459, \n",
            " Training perplexity: 1.0035561472051402\n",
            "___________________________________________________________________________\n",
            "EPOCH: 88\n",
            "Total Steps: 1392\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.0034583254891913384, \n",
            " Training perplexity: 1.0034643123963545\n",
            "___________________________________________________________________________\n",
            "EPOCH: 89\n",
            "Total Steps: 1408\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.0034720029652817175, \n",
            " Training perplexity: 1.003478037349356\n",
            "___________________________________________________________________________\n",
            "EPOCH: 90\n",
            "Total Steps: 1424\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Greedy decoding\n",
            "Sample prompt: Good morning America | generated text:  blood and treasure in endless foreign, ridiculous wars. Countries you’ve never even heard of. In 20\n",
            "\n",
            "Random decoding\n",
            "Sample prompt: Good morning America | generated text:  blood and treasure in endless ridiculous foreign wars in countries you’ve never even heard of for t\n",
            "\n",
            "\n",
            "Greedy decoding\n",
            "Sample prompt: Very good | generated text: relationships in different parts of the world. In some we help. We don’t have to, though. Now we don\n",
            "\n",
            "Random decoding\n",
            "Sample prompt: Very good | generated text: Ronativake evening. You see what happens. It’s just kicking in right now, and one of the biggest ben\n",
            "\n",
            "\n",
            "Greedy decoding\n",
            "Sample prompt: Donald Trump: | generated text: (01:23:15)<eos>We had 45,000 people in Florida last night. By the way, we’re doing very well in Florida.\n",
            "\n",
            "Random decoding\n",
            "Sample prompt: Donald Trump: | generated text: (01:23:15)<eos>We had 45,000 people in Florida last night. By the way, we’re doing very well in Florida.\n",
            "\n",
            "Training Loss: 0.0034506723895901814, \n",
            " Training perplexity: 1.0034566328134118\n",
            "___________________________________________________________________________\n",
            "EPOCH: 91\n",
            "Total Steps: 1440\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.0032954765629256144, \n",
            " Training perplexity: 1.0033009126156351\n",
            "___________________________________________________________________________\n",
            "EPOCH: 92\n",
            "Total Steps: 1456\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.0033011379709932953, \n",
            " Training perplexity: 1.0033065927275948\n",
            "___________________________________________________________________________\n",
            "EPOCH: 93\n",
            "Total Steps: 1472\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.003236816861317493, \n",
            " Training perplexity: 1.0032420610096038\n",
            "___________________________________________________________________________\n",
            "EPOCH: 94\n",
            "Total Steps: 1488\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.003129570875898935, \n",
            " Training perplexity: 1.0031344730954463\n",
            "___________________________________________________________________________\n",
            "EPOCH: 95\n",
            "Total Steps: 1504\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.0029855101747671142, \n",
            " Training perplexity: 1.0029899712486914\n",
            "___________________________________________________________________________\n",
            "EPOCH: 96\n",
            "Total Steps: 1520\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.002881274718674831, \n",
            " Training perplexity: 1.0028854295801513\n",
            "___________________________________________________________________________\n",
            "EPOCH: 97\n",
            "Total Steps: 1536\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.0028100549388909712, \n",
            " Training perplexity: 1.002814006844094\n",
            "___________________________________________________________________________\n",
            "EPOCH: 98\n",
            "Total Steps: 1552\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.0026986123484675772, \n",
            " Training perplexity: 1.002702256880427\n",
            "___________________________________________________________________________\n",
            "EPOCH: 99\n",
            "Total Steps: 1568\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.002631417846714612, \n",
            " Training perplexity: 1.0026348830654694\n",
            "___________________________________________________________________________\n",
            "EPOCH: 100\n",
            "Total Steps: 1584\n",
            "___________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Greedy decoding\n",
            "Sample prompt: Good morning America | generated text:  blood and treasure in endless foreign wars in countries that most of you have never even heard of, \n",
            "\n",
            "Random decoding\n",
            "Sample prompt: Good morning America | generated text:  blood and treasendly in the one sad to stop fidly, and it all everything that happened, terrible th\n",
            "\n",
            "\n",
            "Greedy decoding\n",
            "Sample prompt: Very good | generated text: relationships in different parts of the world. In some we help. We don’t have to, though. Now we don\n",
            "\n",
            "Random decoding\n",
            "Sample prompt: Very good | generated text: ratings that they’ll want to do it again and again.<eos><eos>Donald Trump: (39:14)<eos>But no, wasn’t that terri\n",
            "\n",
            "\n",
            "Greedy decoding\n",
            "Sample prompt: Donald Trump: | generated text: (01:23:15)<eos>We had 45,000 people in Florida last night. By the way, we’re doing very well in Florida.\n",
            "\n",
            "Random decoding\n",
            "Sample prompt: Donald Trump: | generated text: (14:17)<eos>The doctor told me, “Sir, your son has tested positive.” I see some people that want to do h\n",
            "\n",
            "Training Loss: 0.002641220678924583, \n",
            " Training perplexity: 1.0026447117751704\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "trump_samples = ['Good morning America', 'Very good', 'Donald Trump:']\n",
        "PATH = bonus_path\n",
        "trainer = Trainer(model_parameters = model_parameters, path = PATH, bptt_len = BPTT_LEN, samples = trump_samples)\n",
        "counter(PATH)\n",
        "print(\"Vocab Count: \", len(trainer.train_field.vocab))\n",
        "print(\"Count: \", len(trainer.bptt_iterator))\n",
        "trump_model = trainer.train_model(num_epochs=100)\n",
        "torch.save(trump_model.state_dict(), 'trump_model.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Fable and Trump models"
      ],
      "metadata": {
        "id": "i26a5-l_aBLJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fable Model\n",
        "PATH = book_path\n",
        "fable_trainer = Trainer(model_parameters = model_parameters, path = PATH, bptt_len = BPTT_LEN, samples = fable_samples)\n",
        "fable_model = fable_trainer.model\n",
        "fable_model.load_state_dict(torch.load('fable_model.pt'))\n",
        "\n",
        "# Trump Model\n",
        "PATH = bonus_path\n",
        "trump_trainer = Trainer(model_parameters = model_parameters, path = PATH, bptt_len = BPTT_LEN, samples = fable_samples)\n",
        "trump_model = trump_trainer.model\n",
        "trump_model.load_state_dict(torch.load('trump_model.pt'))\n"
      ],
      "metadata": {
        "id": "n_aqoSYxaAtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxxpYCYkGFUy"
      },
      "source": [
        "# Greedy decoding for the fable model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "r4XASfKGGFUz",
        "outputId": "1f5fe6be-73d5-4392-8a8f-3132e25b1f85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Greedy Decoding\n",
            "A title in the book\n",
            "Sample prompt: THE FOX AND THE LION | generated text: <eos><eos>A LITTLE fox was out playing one day, when a Lion came roaring along.<eos>“Dear me,” said the Fox, as he hid behind a tree, “I never saw a Lion<eos>before. What a terrible creature! His voice makes me tremble.”<eos><eos>The next time the Fox met the Lion he was not so much afraid, but he<eos>kept a safe distance and \n",
            "A title in similar style\n",
            "Sample prompt: THE TURTLE AND THE BIRD | generated text: <eos><eos><eos>A WOLF, passing by, saw some Shepherds in a hut, eating for their<eos>dinner a haunch of mutton. Approaching them, he said: “Ah! gentlemen,<eos>you are feasting on mutton. I like your taste. But what a hue and cry<eos>you would raise if _I_ were to do it.”<eos><eos><eos><eos><eos>THE BOY AND THE NETTLE<eos><eos><eos>A BOY was once stung by\n",
            "Some texts in similar style\n",
            "Sample prompt: Back in my day | generated text:  The eggs were large, and<eos>sold for a good price. The Woman often thought, as she took them to<eos>market: “How glad they all are to get my eggs! I could sell as many<eos>more just as easily.”<eos><eos>It began to look a small thing to her to get but a single egg each day.<eos>“If I were to give a double allowance of ba\n",
            "Anything Interesting\n",
            "Sample prompt: Dallmayr to go | generated text: home<eos>with him and see all the beautiful things that are under the water.<eos><eos>“Can you swim?” asked the Frog.<eos><eos>“Not much,” said the Mouse.<eos><eos>[Illustration]<eos><eos>“No matter,” said the Frog; “I will tie your foot to my foot with a<eos>piece of this strong grass, and then I can pull you along nicely.” The<eos>Frog laug\n",
            "Sample prompt: Covid-19 is | generated text: to be disturbed again by the silly Frogs, and this<eos>time he sent them a Stork, saying, “You will have some one to rule<eos>over you now.”<eos><eos>As they saw the Stork solemnly walking down to the lake, they were<eos>delighted.<eos><eos>“Ah!” they said, “see how grand he looks! How he strides along! How he<eos>throws back his \n",
            "Random Decoding\n",
            "A title in the book\n",
            "Sample prompt: THE FOX AND THE LION | generated text: <eos><eos>A LITTLE fox was out playing one day, when a Lion came roaring along.<eos>“Dear me,” said the Fox, as he hid behind a tree, “I never saw a Lion<eos>before. What a terrible creature! His voice makes me tremble.”<eos><eos>The next time the Fox met the Lion he was not so much afraided<eos>given it was, but that one is t\n",
            "A title in similar style\n",
            "Sample prompt: THE TURTLE AND THE BIRD | generated text: <eos><eos><eos>A WOLF, passing by, saw some Skan who was kinly one lion under the feet of a man, you shall have<eos>twenty men burst it.<eos><eos>As there was the best of meat in the ugly.<eos><eos>“It is enough for me, too?”<eos><eos>“You go away.”<eos><eos>“Go, and I can do that as well. I am a beast so much aftery, the<eos>farmer makes you look so\n",
            "Some texts in similar style\n",
            "Sample prompt: Back in my day | generated text:  The eggs were large, and<eos>sold for a good price. The Woman often thought, as she took them to<eos>market: “How glad they all are to get my eggs! I could sell as many<eos>more just as easily.”<eos><eos>It began to look a small thing to her to get but a single egg each day.<eos>“If I were to give a double allowance of ba\n",
            "Anything Interesting\n",
            "Sample prompt: Dallmayr to go | generated text: near him,<eos>even when he found that his old enemy could not move. But he could not<eos>refrain from giving an exulting crow.<eos><eos>The Fox, looking up, said: “Dear Mr. Cock, you see how unlucky I have<eos>been, and all because I came here to inquire a few compliance with the terms of this<eos>agreement and help preser\n",
            "Sample prompt: Covid-19 is | generated text: to be disturbed again by the silly<eos>pertain King stopped by a tree, he let the poor old father has<eos>taken prisoner times in Greece to the rank of<eos>literary form a thousand years before the above-mentioned revival<eos>in Germany, France, and England. As the creation of Æsop it was the<eos>answer to a need for t\n",
            "Sample prompt: The Angry Turtle was | generated text: drowned,<eos>the Blind Man and the Lamb bakeping were makes so crow.<eos><eos>A drincing with fallen found for the use of the world at no cost and with almost no<eos>  restrictions whatsoever. You may copy it, give it away or re-use it under the terms of<eos>the Project Gutenberg License included with this eBook or onl\n",
            "Greedy Decoding\n",
            "A title in the book\n",
            "Sample prompt:   | generated text:                       58<eos>    The Lion and the Mouse                  61<eos>    The Mouse, the Cat, and the Cock       63<eos>    The Ax and the Trees                     65<eos>    The Jackdaw and the Sheep              66<eos>    The Cat and the Cock                   67<eos>    The Wolf and the Goat                 \n",
            "A title in similar style\n",
            "Sample prompt: A very nice day | generated text: which looked outright.<eos><eos>By and by they came to a bridge. Then the Donkey began to kick, and<eos>breaking the rope, fell into the water and was drowned.<eos><eos>The Cock said nothing, but went but to see what it was.<eos><eos>She found that it was flax. “When this flax has grown,” she said to<eos>herself, “the man will mak\n",
            "Sample prompt: I once was | generated text: made a drudge too, and was often<eos>for ready with chatger.<eos><eos>But the Mountain replied: “What good have you done by such generosity?<eos>and how can any one help being pained at the sight of it? If you<eos>had poured your showers over the land, you might have saved a whole<eos>district from famine. But as to the se\n",
            "Anything Interesting\n",
            "Sample prompt: Birds are flying | generated text: outdr.<eos><eos>“I do not care what happens,” said the Fox, “for I have a thousand<eos>tricks, any one of which would get me out of difficulty. But pray, Mrs.<eos>Puss,” he added, “what would you do if there should be an invasion?”<eos><eos>[Illustration]<eos><eos>“I have but one course,” Puss replied. “If that would not serve me,\n",
            "Sample prompt: Coca Cola | generated text: ce.<eos><eos><eos><eos><eos>THE BLIND MAN AND THE LAME MAN<eos><eos><eos>A BLIND Man, being stopped in a bad piece of road, met a Lame Man,<eos>and entreated him to help him out of the difficulty into which he had<eos>fallen.<eos><eos>“How can I,” replied the Lame Man, “since I can scarcely drag myself<eos>along? I am lame, and you look very strong.”\n"
          ]
        }
      ],
      "source": [
        "#Greedy\n",
        "prompt = 'THE FOX AND THE LION'\n",
        "gen_text = trainer.predict(fable_model,prompt,300)\n",
        "print(\"Greedy Decoding\")\n",
        "print(\"A title in the book\")\n",
        "print(f'Sample prompt: {prompt} | generated text: {gen_text}')\n",
        "\n",
        "#A title which you invent, which is not in the book, but similar in the style.\n",
        "prompt = 'THE TURTLE AND THE BIRD'\n",
        "gen_text = trainer.predict(fable_model,prompt,300)\n",
        "print(\"A title in similar style\")\n",
        "print(f'Sample prompt: {prompt} | generated text: {gen_text}')\n",
        "# Some texts in a similar style.\n",
        "print(\"Some texts in similar style\")\n",
        "prompt = 'Back in my day'\n",
        "gen_text = trainer.predict(fable_model,prompt,300)\n",
        "print(f'Sample prompt: {prompt} | generated text: {gen_text}')\n",
        "#Anything you might find interesting\n",
        "print(\"Anything Interesting\")\n",
        "prompt = 'Dallmayr to go'\n",
        "gen_text = trainer.predict(fable_model,prompt,300)\n",
        "print(f'Sample prompt: {prompt} | generated text: {gen_text}')\n",
        "prompt = 'Covid-19 is'\n",
        "gen_text = trainer.predict(fable_model,prompt,300)\n",
        "print(f'Sample prompt: {prompt} | generated text: {gen_text}')\n",
        "#Multinomial\n",
        "print(\"Random Decoding\")\n",
        "print(\"A title in the book\")\n",
        "prompt = 'THE FOX AND THE LION'\n",
        "gen_text = trainer.predict(fable_model,prompt,300,method=\"random\")\n",
        "print(f'Sample prompt: {prompt} | generated text: {gen_text}')\n",
        "#A title which you invent, which is not in the book, but similar in the style.\n",
        "print(\"A title in similar style\")\n",
        "prompt = 'THE TURTLE AND THE BIRD'\n",
        "gen_text = trainer.predict(fable_model,prompt,300,method=\"random\")\n",
        "print(f'Sample prompt: {prompt} | generated text: {gen_text}')\n",
        "# Some texts in a similar style.\n",
        "print(\"Some texts in similar style\")\n",
        "prompt = 'Back in my day'\n",
        "gen_text = trainer.predict(fable_model,prompt,300,method=\"random\")\n",
        "print(f'Sample prompt: {prompt} | generated text: {gen_text}')\n",
        "#Anything you might find interesting\n",
        "print(\"Anything Interesting\")\n",
        "prompt = 'Dallmayr to go'\n",
        "gen_text = trainer.predict(fable_model,prompt,300,method=\"random\")\n",
        "print(f'Sample prompt: {prompt} | generated text: {gen_text}')\n",
        "prompt = 'Covid-19 is'\n",
        "gen_text = trainer.predict(fable_model,prompt,300,method=\"random\")\n",
        "print(f'Sample prompt: {prompt} | generated text: {gen_text}')\n",
        "prompt = 'The Angry Turtle was'\n",
        "gen_text = trainer.predict(fable_model,prompt,300,method=\"random\")\n",
        "print(f'Sample prompt: {prompt} | generated text: {gen_text}')\n",
        "\n",
        "#Greedy\n",
        "print(\"Greedy Decoding\")\n",
        "\n",
        "prompt = ' '\n",
        "gen_text = trainer.predict(fable_model,prompt,300)\n",
        "print(\"A title in the book\")\n",
        "print(f'Sample prompt: {prompt} | generated text: {gen_text}')\n",
        "#A title which you invent, which is not in the book, but similar in the style.\n",
        "prompt = 'A very nice day'\n",
        "gen_text = trainer.predict(fable_model,prompt,300)\n",
        "print(\"A title in similar style\")\n",
        "print(f'Sample prompt: {prompt} | generated text: {gen_text}')\n",
        "# Some texts in a similar style.\n",
        "prompt = 'I once was'\n",
        "gen_text = trainer.predict(fable_model,prompt,300)\n",
        "print(f'Sample prompt: {prompt} | generated text: {gen_text}')\n",
        "#Anything you might find interesting\n",
        "print(\"Anything Interesting\")\n",
        "prompt = 'Birds are flying'\n",
        "gen_text = trainer.predict(fable_model,prompt,300)\n",
        "print(f'Sample prompt: {prompt} | generated text: {gen_text}')\n",
        "prompt = 'Coca Cola'\n",
        "gen_text = trainer.predict(fable_model,prompt,300)\n",
        "print(f'Sample prompt: {prompt} | generated text: {gen_text}')\n",
        "#Multinomial\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMM2BNGNGFUz"
      },
      "source": [
        "# Random decoding for the fable model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "6kKgQ-A0GFU0",
        "outputId": "7de6b9e2-72ee-4805-ec0b-be208735005e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Decoding\n",
            "Sample prompt:   | generated text: nr.n, a Juhhreh stood up aid sard, W1rhs, I drmmeh yrtn cou<eos>ynollcb vnehe rs io gatehral moh hesrstai.e e7ual to a .okehriw om<eos>nrdes, aid iotnriw ri tne pheseit .ase so wood as leatnehb0<eos><eos>     q       q       q<eos><eos>:kehc gai moh nrs oyi thadeb<eos><eos><eos><eos><eos>vA: ATB:1 T)D vA: 2B(M1<eos><eos><eos>I) T 2(B:1v, deep, snadc, aid\n",
            "Sample prompt: A very nice day | generated text: ed, tne Jo.’, as usual, fewai to .hoyb<eos><eos>T 2o4, neahriw tne souid aid tnri’riw ne yas suhe om a wood fhea’mast,<eos>.age aid stood uideh tne fhai.nesb WMood gohiriw,0 sard ne to tne Jo.’b<eos><eos>WAoy wlad I ag to ga’e tne a4 ri nrs goutn5 aid neh srstehdc .ogplcriw<eos>yrtn tnese mell rito tne yateh aid<eos>tnus ga’e \n",
            "Sample prompt: I once was | generated text: eied fc tne eitheated tnrs<eos>theatgeit, a..used nrg om rgpretc aid, ri sprte om nrs sa.hed .naha.teh<eos>as agfassadoh, e4e.uted nrg as a puflr. .hrgrialb 3ut tne 3rhds yould nake<eos>iotnriw gohe to do yrtn tneg, fut lemt tne yoods ynehe tnec lrked aid<eos>.age ri tne dactrge, fut at tnrs om tne souid om<eos>mootste\n",
            "Anything Interesting\n",
            "Sample prompt: Birds are flying | generated text: he ri gridb vne<eos>pehsoi snould fe om gohe kalue tnai nrs .oatb0<eos><eos><eos><eos><eos>vA: D(M1 T)D vA: AID:1<eos><eos><eos>1(P: Dows, magrsned yrtn nuiweh, say .oynrdes steepriw ri a hrkeh,<eos>.lose fc a taiiehc, aid tnouwnt tnec grwnt fe eateib )ot feriw afle to<eos>hea.n tneg, tnec set to yoh’ mrhst to dhri’ up tne hrkeh, fut fuhst<eos>tn\n",
            "Sample prompt: Coca Cola | generated text: e<eos>om a .ogpahrsoi om tne tyo heidehriws,<eos>aid su.n a .ogpahrsoi yrll opei tne yac to a drs.ussroi om<eos>tne moolrsn Pouseb<eos><eos><eos><eos><eos>vA: 1A:HA:BDO1 3(N T)D vA: ?(S2<eos><eos><eos>T PT) yno nad a mrie mlo.’ om 1neep put tneg all rito a mreld, aid<eos>nrhed a Jo.’ to nrs gouselr’e nead aid<eos>eahs, ynr.n so .oimused tne ?easel tn\n",
            "Sample prompt: The Fox | generated text: Xaid yno su.n lr’ed ri tne<eos>  frwnt, aid .at.nriw tne 2o4, ne sardx<eos><eos>WJehs” I yrll let hetuhi to tnrs 7uret pla.eb0<eos><eos>XIllusthatroi&<eos><eos>Tmteh feriw uhwed a loiw trge, tne Jouithc Pouse at last awheed to wo<eos>to tne .rtc tnat kehc irwntb 1o tnec stahted omm towetneh, aid afout<eos>grdirwnt .age to tne wheat no\n",
            "Sample prompt: The Angry Turtle was | generated text: ed, aid tne Aay’<eos>.ooped doyi aid siat.ned at nrs gasteh as wood ri yriwb<eos><eos>Ae strlled ri rts wheat .lustehs om hrpe, fla.’<eos>whapes naiwriw mhog a thellrsed krieb<eos><eos>W?nat lu.’”0 ne sard5 Wrm oilc tnec yeheiOt 7urte so nrwn, I snould<eos>fe suhe om a mrie meastb I yoideh rm I .ai wet tnegb I .ai tnri’ om<eos>iot\n"
          ]
        }
      ],
      "source": [
        "print(\"Random Decoding\")\n",
        "prompt = ' '\n",
        "gen_text = trainer.predict(fable_model,prompt,300,method=\"random\")\n",
        "print(f'Sample prompt: {prompt} | generated text: {gen_text}')\n",
        "#A title which you invent, which is not in the book, but similar in the style.\n",
        "prompt = 'A very nice day'\n",
        "gen_text = trainer.predict(fable_model,prompt,300,method=\"random\")\n",
        "print(f'Sample prompt: {prompt} | generated text: {gen_text}')\n",
        "# Some texts in a similar style.\n",
        "prompt = 'I once was'\n",
        "gen_text = trainer.predict(fable_model,prompt,300,method=\"random\")\n",
        "print(f'Sample prompt: {prompt} | generated text: {gen_text}')\n",
        "#Anything you might find interesting\"\n",
        "print(\"Anything Interesting\")\n",
        "prompt = 'Birds are flying'\n",
        "gen_text = trainer.predict(fable_model,prompt,300,method=\"random\")\n",
        "print(f'Sample prompt: {prompt} | generated text: {gen_text}')\n",
        "prompt = 'Coca Cola'\n",
        "gen_text = trainer.predict(fable_model,prompt,300,method=\"random\")\n",
        "print(f'Sample prompt: {prompt} | generated text: {gen_text}')\n",
        "prompt = 'The Fox'\n",
        "gen_text = trainer.predict(fable_model,prompt,300,method=\"random\")\n",
        "print(f'Sample prompt: {prompt} | generated text: {gen_text}')\n",
        "\n",
        "prompt = 'The Angry Turtle was'\n",
        "gen_text = trainer.predict(fable_model,prompt,300,method=\"random\")\n",
        "print(f'Sample prompt: {prompt} | generated text: {gen_text}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YED1sEBHGFU1"
      },
      "source": [
        "# Greedy decoding for the trump model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "OKqZ-BakGFU1",
        "outputId": "4ec8e58e-bafb-42de-c29e-ffb57aec5f6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Greedy Decoding\n",
            "Sample prompt: Thank You | generated text:  he’s going to introduce people to who? To his fantastic. She is my favorite Senator from the State of Nebraska, by far, by far. She’s fantastic. She is. I’ll tell you what she calls me, it doesn’t stop. Between her and Joni Ernst from Iowa, who I think is here, where’s Joni? Joni. Joni. They call, \n",
            "Sample prompt: Good | generated text:  You lost 27 First Lady, it’s true, they love her. She’s doing a good job. They love … the whole family back there, they love that family back there. Great family, hi, Tiffany. So, Melania has it but she knocked it out pretty good. And I did a great job. I was surrounded by these doctors, 12 doctors\n",
            "Sample prompt: China | generated text: into the World Trade Organization, which you supported, extending most favored nation status to China, which you supported, those steps allowed China to take advantage of the United States by using our own open trade deals against us.<eos><eos>Joe Biden: (22:45)<eos>No.<eos><eos>Speaker 1: (22:45)<eos>Do you think in retro\n",
            "Sample prompt: We have to | generated text: get a little more than that. They said two points today. The great Ted Nugent. Ted. Ted. Great, Ted. He’s the only one really dressed properly. Thank you, Ted, very good. Great job. We appreciate it Ted. The president of the Police Officers Association of Michigan, Jim Tignanelli. Jim. He’s like cen\n"
          ]
        }
      ],
      "source": [
        "#Greedy\n",
        "prompt = 'Thank You'\n",
        "gen_text = trainer.predict(trump_model,prompt,300)\n",
        "print(\"Greedy Decoding\")\n",
        "print(f'Sample prompt: {prompt} | generated text: {gen_text}')\n",
        "#A title which you invent, which is not in the book, but similar in the style.\n",
        "prompt = 'Good'\n",
        "gen_text = trainer.predict(trump_model,prompt,300)\n",
        "print(f'Sample prompt: {prompt} | generated text: {gen_text}')\n",
        "# Some texts in a similar style.\n",
        "prompt = 'China'\n",
        "gen_text = trainer.predict(trump_model,prompt,300)\n",
        "print(f'Sample prompt: {prompt} | generated text: {gen_text}')\n",
        "#Anything you might find interesting\n",
        "prompt = 'We have to'\n",
        "gen_text = trainer.predict(trump_model,prompt,300)\n",
        "print(f'Sample prompt: {prompt} | generated text: {gen_text}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbVBsPwsGFU1"
      },
      "source": [
        "# Random decoding for the trump model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "axOZ54UGGFU1",
        "outputId": "bff0bd30-71e3-478f-e003-6231828cf825",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Decoding\n",
            "Sample prompt: Thank You | generated text:  he’s going to introduce people to who’s fine higher. Wis corn it a few and we can talk about the way that was the state of Michigan, and we’re going to win four more years in the White House. By the way, there has never been a campaign …<eos><eos>Donald Trump: (08:47)<eos>There has never been a campaign, in th\n",
            "Sample prompt: Good | generated text:  You know, I have a lot of my kids here tonight. Could you imagine if my kids said, “Yeah, dad, I got a billion and a half dollars from China.” Oh, I don’t think they’d want to write about that, the fake news. Do you think they’d write about that? Then he gets three and a half million dollars from t\n",
            "Sample prompt: China | generated text: is not like that. President Putin of Russia. There’s nobody been tougher than Russia. And I hope you can hear. Can you hear it back there by the way?<eos><eos>Audience: (03:33:31)<eos>No!<eos><eos>President Donald J. Trump: (03:34)<eos>Yes, no?<eos><eos>Audience: (03:35)<eos>No!<eos><eos>President Donald J. Trump: (03:38)<eos>Hold it. Okay. That \n",
            "Sample prompt: We have to | generated text: get a little more federal targeted. A vote on early and they’re very simple choice. Do you want to be ruled by the corrupt and selfless political maniacs that you’re dealing with? Or do you want to be ruled by the American people? You’re supposed to be ruled by the American people. Do you want to be\n",
            "Sample prompt:   | generated text: ith, I don’t know… You been to caucus. No you haven’t. You’re a lying dog-faced pony soldier.<eos><eos>Vice President Mike Pence: (02:16:42)<eos>[inaudible 02:16:42] Why, why, why, why, why, why, why, why, why you’re getting nervous, man.<eos><eos>Vice President Mike Pence: (02:16:45)<eos>What kind of country we’re going to be? Four more years of George [inaudible 02:16:49] going to find ourselves in a position where, if Trump gets elected, we’re going to be in a different world.<eos><eos>Vice President Mike Pence: (02:16:58)<eos>Lie, after lie, after lie, after lie.<eos><eos>Vice President Mike Pence: (02:17:03)<eos>You know, we have to come together. That’s why I’m running. I’m running as a proud Democrat for the Senate. And by the way, I sit on the stand and it get hot, I got hairy legs that turn blonde in the sun. And the kids used to come up and reach in the pool and rub my leg down. So it was straight and then watch the hair come back up again. They’d look at it. So I learned about roaches, I learned about kids jumping on my l\n",
            "Sample prompt:   | generated text: ant your children to be safe, if you want your values to be honored, if you want your life to be treated with dignity and respect, then I am asking you to go to the poll tomorrow and vote, vote, vote. Remember what I said four years ago. I am your voice, and we will make America great again, and that’s what we’re doing. For the last four years, the depraved swamp has tried everything to stop me and to stop you, because they know I don’t answer to them. I answer to you. That’s why we’re here. That’s why we’re here. Together we will defeat the corrupt establishment. Which is under siege, but it’s 100% secure with us in this position, Mike, right? We will never touch it.<eos><eos>Donald Trump: (02:29:32)<eos>We inherit the legacy of American patriots who gave their blood, sweat, and tears to defend our country, our families, and our freedom. We stand on the shoulders of American heroes who crossed the ocean, settled the continent, tamed the wilderness, laid down the railroads, raised up the great sky\n",
            "Something not in the text\n"
          ]
        }
      ],
      "source": [
        "print(\"Random Decoding\")\n",
        "prompt = 'Thank You'\n",
        "gen_text = trainer.predict(trump_model,prompt,300,method=\"random\")\n",
        "print(f'Sample prompt: {prompt} | generated text: {gen_text}')\n",
        "#A title which you invent, which is not in the book, but similar in the style.\n",
        "prompt = 'Good'\n",
        "gen_text = trainer.predict(trump_model,prompt,300,method=\"random\")\n",
        "print(f'Sample prompt: {prompt} | generated text: {gen_text}')\n",
        "# Some texts in a similar style.\n",
        "prompt = 'China'\n",
        "gen_text = trainer.predict(trump_model,prompt,300,method=\"random\")\n",
        "print(f'Sample prompt: {prompt} | generated text: {gen_text}')\n",
        "#Anything you might find interesting\n",
        "prompt = 'We have to'\n",
        "gen_text = trainer.predict(trump_model,prompt,300,method=\"random\")\n",
        "print(f'Sample prompt: {prompt} | generated text: {gen_text}')\n",
        "prompt = ' '\n",
        "gen_text = trainer.predict(trump_model,prompt,1000,method=\"greedy\")\n",
        "print(f'Sample prompt: {prompt} | generated text: {gen_text}')\n",
        "prompt = ' '\n",
        "gen_text = trainer.predict(trump_model,prompt,1000,method=\"random\")\n",
        "print(f'Sample prompt: {prompt} | generated text: {gen_text}')\n",
        "print(\"Something not in the text\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhB1N00bGFU2"
      },
      "source": [
        "# Comparing random and greedy for both models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "wijMZenWGFU2",
        "outputId": "56457471-f765-4c99-e5e5-5fe4340b0f31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Decoding\n",
            "Sample prompt: Birds fly high | generated text: tnriw tnat rt yas<eos>so wood as aiotneh, a pehme.t gahkelb (ilc oie tnriw<eos>rs uilu.’c[tne 17urhhel nas loiw awo lost all nrs teetnb<eos><eos><eos><eos><eos>vA: ?(S2 T)D vA: JTv<eos><eos><eos>T ?(S2 hai out om tne mohest rito a krllawe[iot to pac a krsrt, fut to<eos>sake rts lrme5 moh rt thegfled moh rts s’rib<eos><eos>vne nuitsgai aid a pa.’ om n\n",
            "Greedy Decoding\n",
            "Sample prompt: Birds fly high | generated text: l ri aid ri daiweh mhog tne wheat<eos>.lugsc .heatuhe, .alled out, WAelp” nelp”0 aid tne sehkaits, huiiriw<eos>ri, dhoke tne Doi’ec out om doohs yrtn str.’s aid stoiesb<eos><eos><eos><eos><eos>vA: ():“:N:D D(:<eos><eos><eos>T D(:, flrid ri oie ece, used to wha-e as ieah as sne .ould to tne edwe<eos>om a .lrmm, so tnat sne grwnt ’eep neh flrid\n",
            "Sample prompt: <eos> | generated text: 3hoyi“f<eos><eos>    vne vhugpeteh tnat tne HhoYe.t Muteifehw Srtehahc Th.nrke 2ouidatroi rs a ioi phomrt<eos>ULCR.8R68 edu.atroial .ohpohatroi ohwair-ed uideh tne lays om tne<eos>state om Prssrssrppr aid whaited ta4 e4egpt status fc tne Iitehial<eos>Bekeiue 1ehkr.eb vne 2ouidatroi–s :I) oh medehal ta4 rdeitrmr.atroi<eos>iugfeh rs KE“KFFCUECb Joithrfutrois to tne HhoYe.t Muteifehw Srteha<eos><eos><eos>vne ?olm yas prpriw aid tne …rd yas dai.riw, soge Dows, neahriw tne<eos>gusr., hai to tne pla.e to see ynat yas woriw oi5 aid tne ?olm yas wlad<eos>to ta’e nrgselm omm as mast as nrs lews yould .ahhc nrgb<eos><eos><eos><eos><eos>vA: AT?… T)D vA: )IMAvI)MTS:<eos><eos>\n",
            "Sample prompt: <eos> | generated text: 3hoyi“fa.’, Mhac“eah, aid<eos>?nrte“ynrs’ehb<eos><eos>Wvnehe rs io .ogmoht ri tne nouse,0 sard 3hoyi“fa.’b WIm I fut step<eos>rito tne paithc to pr.’ up a mey .hugfs, doyi .oges tne Jat, aid I nake<eos>nahdlc trge to hui to gc iest awarib0<eos><eos>W?nat .ai ye doG0 as’ed Mhac“eahb W1nall ye all hui at neh at oi.e aid<eos>frte neh, aid mhrwntei neh ayacG0<eos><eos>W)o,0 sard tne mrhst, WI mouid tne a4b It rs grieb0<eos><eos>vnec nad iot woie mah ynei tnec neahd tne oyieh om tne a4 puhsuriw<eos>tneg, aid tnec yehe old, aid .ahhcriw tneg, ynei he7urhed, mhog pla.e<eos>to pla.e upoi nrs fa.’b<eos><eos>WTll tnrs gac fe thue,0 heplred tne Ausfaidgai5 Wfut, as I\n",
            "Sample prompt: THE WOLF AND THE LAMB | generated text: C<eos>      FFCU<eos>      vne ?( aid tne 1yai                  C9<eos>    vne Pooi aid neh Potneh               C9K<eos>    vne Aohse aid tne 1taw              C9K<eos>    vne Joui.rl nelp ta’ei tnat oi a couiw           CL9<eos>    vne Doi’ec aid tne Sap Dow          CC$<eos>    vne (a’ aid tne Beed                  CC$<eos>    vne Dow aid tne Aahe                  CC$<eos>    vne Tits aid tne Mhassnoppehs          $6<eos>    vne Miat aid tne 3ull                   $U<eos>    vne 3uidle om 1tr.’s                CEL<eos>    vne Prs.nrekous Dow                     CUC<eos>    vne Dow aid tne Aahe                  CC<eos>    vne Tits aid tne Mhassnoppehs          C6<eos>    vne 2hows yno as’ed moh a …riw        CU<eos>    vne Doi’ec ri tne SroiOs 1’ri          C9<eos>    vne Pr.e ri Joui.rl                   FL<eos>    vne …rd aid tne ?olm                     CKC<eos>    vne Mouhd aid tne Hrie              C6!<eos>    vne Aay’, …rte, aid Hrweois           CFL<eos>    vne ?ah Aohse aid tne Pule            CLC<eos>    vne ?olm aid tne Moat                C6E<eos>    vne ?olm aid\n",
            "Sample prompt: THE WOLF AND THE LAMB | generated text: C<eos>      vne Dow ri tne Paiweh                       FF$<eos>    vne Pouse, tne 2how, aid tne Aay’     FF$<eos>    vne 1nepnehd 3oc aid tne ?olm         FF!<eos>    vne 2rsnehgai aid tne Srttle 2rsn     FF9<eos>    vne 2o4 aid tne Jhoy                   FF9<eos>    vne Hahthrdwe aid tne 2oyleh            F6L<eos>    vne vnrhstc Hrweoi                        E9<eos>    vne vnhee vhadesgei                           F6C<eos>    vne Aahes aid tne 2hows                   UL<eos>    vne :awle aid tne Thhoy                  U6<eos>    vne :awle aid tne 2o4                    UU<eos>    vne Dhug aid tne zase om 1yeet Aehfs   U$<eos>    vne vyo 2hows                                                        E9<eos>    vne Hahthrdwe aid tne 2oyleh           E!<eos>    vne vnrhstc Hrweoi                        E9<eos>    vne vnhee vhadesgei                             F6C<eos>    vne Aahes aid tne 2hows                   UL<eos>    vne :awle aid tne Thhoy                  U6<eos>    vne :awle aid tne 2o4                    UU<eos>    vne Dhug aid tne zase om 1yeet Aehfs   U$\n",
            "Greedy Decoding\n",
            "Sample prompt: President Donald J. Trump:  | generated text: 01:14)<eos>Thank you very much and hello, Kenosha. It’s nice to be back. It’s nice to be back. We spent a little time with you, a little law and order. We brought law and order to Kenosha. Right? That’s what we want. And hello, Wisconsin. Big day, tomorrow, big, big day, big day. And I think we’re going to do very well in Wisconsin just like we did four years ago. And it’s an honor to be with you. Thank you.<eos><eos>Audience: (01:41)<eos>USA! USA! USA! USA! USA! USA! USA! USA! USA! USA! USA! USA! USA! USA! USA! USA! USA! USA! USA! USA! USA! USA! USA! USA! USA! USA! USA! USA! USA! USA! USA! USA! USA! USA! USA\n",
            "Random Decoding\n",
            "Sample prompt: President Donald J. Trump:  | generated text: 01:14)<eos>Thank you very much and hello, Kenosha. It’s nice to be back. It’s nice to be back. We spent a little time with you, a little law and order. We brought law and order to Kenosha. Right? That’s what we want. And hello, Wisconsin. Big day, tomorrow, big, big day, big day. And I think we’re going to do very well in Wisconsin just like we did four years ago. And it’s an honor to be with you. Thank you.<eos><eos>Audience: (01:41)<eos>USA! USA! USA! USA! USA! USA! USA! USA! USA!<eos><eos>Donald Trump: (01:41:08)<eos>It’s a great group. Thank you. Thank you very much. We appreciate it. Next year will be the greatest e\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"Random Decoding\")\n",
        "prompt = 'Birds fly high'\n",
        "gen_text = trainer.predict(fable_model,prompt,300,method=\"random\")\n",
        "print(f'Sample prompt: {prompt} | generated text: {gen_text}')\n",
        "prompt = 'Birds fly high'\n",
        "print(\"Greedy Decoding\")\n",
        "gen_text = trainer.predict(fable_model,prompt,300,method=\"greedy\")\n",
        "print(f'Sample prompt: {prompt} | generated text: {gen_text}')\n",
        "prompt = '<eos>'\n",
        "gen_text = trainer.predict(fable_model,prompt,600,method=\"random\")\n",
        "print(f'Sample prompt: {prompt} | generated text: {gen_text}')\n",
        "gen_text = trainer.predict(fable_model,prompt,600,method=\"greedy\")\n",
        "print(f'Sample prompt: {prompt} | generated text: {gen_text}')\n",
        "\n",
        "prompt = 'THE WOLF AND THE LAMB'\n",
        "gen_text = trainer.predict(fable_model,prompt,1000,method=\"random\")\n",
        "print(f'Sample prompt: {prompt} | generated text: {gen_text}')\n",
        "prompt = 'THE WOLF AND THE LAMB'\n",
        "gen_text = trainer.predict(fable_model,prompt,1000,method=\"greedy\")\n",
        "print(f'Sample prompt: {prompt} | generated text: {gen_text}')\n",
        "\n",
        "\n",
        "print(\"Greedy Decoding\")\n",
        "prompt = \"President Donald J. Trump: \"\n",
        "gen_text = trainer.predict(trump_model,prompt,600,method=\"greedy\")\n",
        "print(f'Sample prompt: {prompt} | generated text: {gen_text}')\n",
        "print(\"Random Decoding\")\n",
        "prompt = \"President Donald J. Trump: \"\n",
        "gen_text = trainer.predict(trump_model,prompt,600,method=\"random\")\n",
        "print(f'Sample prompt: {prompt} | generated text: {gen_text}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fu9GwmFrX72t"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.8.3 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
      }
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}